{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. credit approval 자료에 대하여 입력 특징 및 기계학습모델의 함수적인 구조를 설명한다. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp; 1-A. 데이터 입력 특징 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp; 1-A-1. Data Set Information (credit approval): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp; 1. 이 데이터셋은 신용카드 대출 승인여부와 관련 데이터이다. <br>\n",
    "&emsp;&emsp;&emsp; 2. 모든 속성(Attribute)들의 이름 값은 의미 없는 심볼(symbol)로 대체되어 있으며, 연속형(continous), 범주형(nominal) 데이터로 구성되어 있다.<br>\n",
    "&emsp;&emsp;&emsp; 3. 그리고 몇개의 데이터 값들에 결측치가 존재한다. <br>\n",
    "&emsp;&emsp;&emsp;&emsp; * Continuous, Nominal with Small Numbers of values(NSN), and Nominal with Larger Numbers of values(NLN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp; 1-A-2. Attribute Information: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp; A1: NSN(b,a) &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;    A2: Continuous &emsp;&emsp;&emsp;&emsp; A3: Continuous <br>\n",
    "&emsp;&emsp;&emsp; A4: NLN(u, y, l, t) &emsp;&emsp;&emsp;&emsp; A5: NLN(g, p, gg) &emsp;&emsp;&emsp;&emsp; A6: NLN(c, d, cc, i, j, k, m, r, q, w, x, e, aa, f) <br>\n",
    "&emsp;&emsp;&emsp; A7: NLN(v, h, bb, j, n, z, dd, ff, o) &emsp;&emsp;&emsp;&emsp; A8: Continuous &emsp;&emsp;&emsp;&emsp; A9: NSN(t, f) <br>\n",
    "&emsp;&emsp;&emsp; A10: NSN(t, f) &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; A11: Continuous &emsp;&emsp;&emsp;&emsp; A12: NSN(t, f) <br>\n",
    "&emsp;&emsp;&emsp; A13: NLN(g, p, s) &emsp;&emsp;&emsp;&emsp; A14: Continuous &emsp;&emsp;&emsp;&emsp; A15: Continuous &emsp;&emsp;&emsp;&emsp; A16: Class Attribute(+,-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp; 1-A-3 학습 전 데이터 전처리 수행 방향"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp; 1. 결측치가 포함된 Attribute(A1, A2, A4, A5, A6, A7, A14)에 대한 처리가 필요함 <br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - 예측 모델을 만들 예정이므로, 모델 학습 시 모든 정보가 포함된 입력 값이 들어가야함<br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - Nominal Type의 Attribute의 최빈값을 사용하거나, Continuous Type의 평균값으로 대체하는 것은 모델에 왜곡을 발생시킬 수 있음<br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - 따라서 결측치가 포함된 행을 제거하는 과정을 수행할 예정<br>\n",
    "&emsp;&emsp;&emsp; 2. 기계학습 모델의 입력은 숫자 형태의 타입으로 표현되어야 함<br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - 따라서 Nominal형태의 입력을 0과 1형태의 Onehot 인코딩을 수행할 예정<br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - Continuous 형태의 입력이나 string으로 type으로 인식된 모델을 Numerical(float) 형태로 변환 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp; 1-A-4 학습 전 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### &emsp;&emsp;&emsp; 1. Dataframe 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "df = pd.read_csv('.\\dataset.csv', header=None)\n",
    "column_name=['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','A15','A16']\n",
    "df.columns =column_name\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### &emsp;&emsp;&emsp; 2. 데이터 타입 및 결측치 파악 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      "A1     678 non-null object\n",
      "A2     678 non-null object\n",
      "A3     690 non-null float64\n",
      "A4     684 non-null object\n",
      "A5     684 non-null object\n",
      "A6     681 non-null object\n",
      "A7     681 non-null object\n",
      "A8     690 non-null float64\n",
      "A9     690 non-null object\n",
      "A10    690 non-null object\n",
      "A11    690 non-null int64\n",
      "A12    690 non-null object\n",
      "A13    690 non-null object\n",
      "A14    677 non-null object\n",
      "A15    690 non-null int64\n",
      "A16    690 non-null object\n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.replace('?', np.nan, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### &emsp;&emsp;&emsp; 3. 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 653 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      "A1     653 non-null object\n",
      "A2     653 non-null object\n",
      "A3     653 non-null float64\n",
      "A4     653 non-null object\n",
      "A5     653 non-null object\n",
      "A6     653 non-null object\n",
      "A7     653 non-null object\n",
      "A8     653 non-null float64\n",
      "A9     653 non-null object\n",
      "A10    653 non-null object\n",
      "A11    653 non-null int64\n",
      "A12    653 non-null object\n",
      "A13    653 non-null object\n",
      "A14    653 non-null object\n",
      "A15    653 non-null int64\n",
      "A16    653 non-null object\n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### &emsp;&emsp;&emsp; 4. Continous 값 Numerical 데이터 타입으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 653 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      "A1     653 non-null object\n",
      "A2     653 non-null float64\n",
      "A3     653 non-null float64\n",
      "A4     653 non-null object\n",
      "A5     653 non-null object\n",
      "A6     653 non-null object\n",
      "A7     653 non-null object\n",
      "A8     653 non-null float64\n",
      "A9     653 non-null object\n",
      "A10    653 non-null object\n",
      "A11    653 non-null int64\n",
      "A12    653 non-null object\n",
      "A13    653 non-null object\n",
      "A14    653 non-null int64\n",
      "A15    653 non-null int64\n",
      "A16    653 non-null object\n",
      "dtypes: float64(3), int64(3), object(10)\n",
      "memory usage: 86.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df[df.columns[1]] = pd.to_numeric(df[df.columns[1]])\n",
    "df[df.columns[2]] = pd.to_numeric(df[df.columns[2]])\n",
    "df[df.columns[7]] = pd.to_numeric(df[df.columns[7]])\n",
    "df[df.columns[13]] = pd.to_numeric(df[df.columns[13]])\n",
    "df[df.columns[14]] = pd.to_numeric(df[df.columns[14]])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### &emsp;&emsp;&emsp; 5. Nominal Value One Hot Encoding 수행 및 전처리된 Data Frame 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A1_a</th>\n",
       "      <th>A1_b</th>\n",
       "      <th>A4_l</th>\n",
       "      <th>A4_u</th>\n",
       "      <th>...</th>\n",
       "      <th>A9_f</th>\n",
       "      <th>A9_t</th>\n",
       "      <th>A10_f</th>\n",
       "      <th>A10_t</th>\n",
       "      <th>A12_f</th>\n",
       "      <th>A12_t</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "      <th>A16_+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>30.00</td>\n",
       "      <td>5.290</td>\n",
       "      <td>2.250</td>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>22.83</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>20.42</td>\n",
       "      <td>1.835</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>30.58</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>30.67</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A2     A3     A8  A11  A14  A15  A1_a  A1_b  A4_l  A4_u  ...    A9_f  \\\n",
       "521  30.00  5.290  2.250    5   99  500     1     0     0     1  ...       0   \n",
       "522  22.83  3.000  1.290    1  260  800     0     1     0     1  ...       0   \n",
       "131  20.42  1.835  2.250    1  100  150     0     1     0     1  ...       0   \n",
       "442  30.58  2.710  0.125    0   80    0     0     1     0     0  ...       1   \n",
       "274  30.67  2.500  2.250    0  340    0     0     1     0     1  ...       1   \n",
       "\n",
       "     A9_t  A10_f  A10_t  A12_f  A12_t  A13_g  A13_p  A13_s  A16_+  \n",
       "521     1      0      1      0      1      1      0      0      1  \n",
       "522     1      0      1      1      0      1      0      0      1  \n",
       "131     1      0      1      1      0      1      0      0      1  \n",
       "442     0      1      0      0      1      0      0      1      0  \n",
       "274     0      1      0      0      1      0      0      1      0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_lists = list(df.select_dtypes(include=['object']).columns)\n",
    "object_lists\n",
    "for object_list in object_lists:\n",
    "    df = pd.concat([df,pd.get_dummies(df[object_list], prefix=str(object_list))],axis=1)\n",
    "\n",
    "df0 = df.drop(columns=object_lists)\n",
    "df0 = df0.drop(df0.columns[-1], axis=1)\n",
    "df0 = shuffle(df0)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 653 entries, 0 to 689\n",
      "Data columns (total 58 columns):\n",
      "A1       653 non-null object\n",
      "A2       653 non-null float64\n",
      "A3       653 non-null float64\n",
      "A4       653 non-null object\n",
      "A5       653 non-null object\n",
      "A6       653 non-null object\n",
      "A7       653 non-null object\n",
      "A8       653 non-null float64\n",
      "A9       653 non-null object\n",
      "A10      653 non-null object\n",
      "A11      653 non-null int64\n",
      "A12      653 non-null object\n",
      "A13      653 non-null object\n",
      "A14      653 non-null int64\n",
      "A15      653 non-null int64\n",
      "A16      653 non-null object\n",
      "A1_a     653 non-null uint8\n",
      "A1_b     653 non-null uint8\n",
      "A4_l     653 non-null uint8\n",
      "A4_u     653 non-null uint8\n",
      "A4_y     653 non-null uint8\n",
      "A5_g     653 non-null uint8\n",
      "A5_gg    653 non-null uint8\n",
      "A5_p     653 non-null uint8\n",
      "A6_aa    653 non-null uint8\n",
      "A6_c     653 non-null uint8\n",
      "A6_cc    653 non-null uint8\n",
      "A6_d     653 non-null uint8\n",
      "A6_e     653 non-null uint8\n",
      "A6_ff    653 non-null uint8\n",
      "A6_i     653 non-null uint8\n",
      "A6_j     653 non-null uint8\n",
      "A6_k     653 non-null uint8\n",
      "A6_m     653 non-null uint8\n",
      "A6_q     653 non-null uint8\n",
      "A6_r     653 non-null uint8\n",
      "A6_w     653 non-null uint8\n",
      "A6_x     653 non-null uint8\n",
      "A7_bb    653 non-null uint8\n",
      "A7_dd    653 non-null uint8\n",
      "A7_ff    653 non-null uint8\n",
      "A7_h     653 non-null uint8\n",
      "A7_j     653 non-null uint8\n",
      "A7_n     653 non-null uint8\n",
      "A7_o     653 non-null uint8\n",
      "A7_v     653 non-null uint8\n",
      "A7_z     653 non-null uint8\n",
      "A9_f     653 non-null uint8\n",
      "A9_t     653 non-null uint8\n",
      "A10_f    653 non-null uint8\n",
      "A10_t    653 non-null uint8\n",
      "A12_f    653 non-null uint8\n",
      "A12_t    653 non-null uint8\n",
      "A13_g    653 non-null uint8\n",
      "A13_p    653 non-null uint8\n",
      "A13_s    653 non-null uint8\n",
      "A16_+    653 non-null uint8\n",
      "A16_-    653 non-null uint8\n",
      "dtypes: float64(3), int64(3), object(10), uint8(42)\n",
      "memory usage: 113.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp; 1-B. 기계학습 모델의 함수적인 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp; 1-B-1. 위의 데이터셋으로 생성되는 기계학습 모델의 입력(Input), 출력(Output) 구조는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp; 1. Output: Class Attribute (A16) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - binary 구조의 형태로 출력 표현됨 <br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - 대출승인이 허가되면 1, 대출승인이 불허되면 0 <br>\n",
    "&emsp;&emsp;&emsp; 2. Input: Class Attribute를 제외한 모든 Attribute (A1, A2, ~ , A15) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - Norminal Attribute: 0, 1 형태로 변환됨 <br>\n",
    "&emsp;&emsp;&emsp;&emsp;  - Continous Attribute: float 형태로 변환됨 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 위에서 설명한 학습모델의 평가방법을 사용하여 각 학습모델에 대한 평가의 측도를 정리한다. (20 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp; 3-A. Decision Tree (Canonical Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Methods 10th-Mean values for Decision Tree\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Accuracy  0.8636829836829836\n",
      "Precision  0.7972997150277074\n",
      "Recall  0.940554777466542\n",
      "F1  0.8599085151379768\n"
     ]
    }
   ],
   "source": [
    "aAccuracy = np.ones((1,10))\n",
    "aPrecision = np.ones((1,10))\n",
    "aRecall = np.ones((1,10))\n",
    "aF1 = np.ones((1,10))\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "i = 0\n",
    "for train, test in kf.split(df):\n",
    "    y_train = df.iloc[train][df0.columns[-1]]\n",
    "    x_train = df0.iloc[train].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    y_test = df0.iloc[test][df0.columns[-1]]\n",
    "    x_test = df0.iloc[test].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 1, random_state = 1224)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test.values, predicted).ravel()    \n",
    "    \n",
    "    Accuracy  = (TP+TN)/(TP+TN+FP+FN)\n",
    "    Precision = (TP)/(TP+FP)\n",
    "    Recall = (TP)/(TP+FN)\n",
    "    F1 = (2*Precision*Recall)/(Precision + Recall)\n",
    "    \n",
    "    aAccuracy[0][i] = Accuracy\n",
    "    aPrecision[0][i] = Precision\n",
    "    aRecall[0][i] = Recall\n",
    "    aF1[0][i] = F1\n",
    "\n",
    "    i = i + 1    \n",
    "    report = classification_report(y_test.values, predicted)\n",
    "\n",
    "i = 0    \n",
    "print(\"Evaluation Methods 10th-Mean values for Decision Tree\")    \n",
    "print(\"-\"*50)    \n",
    "print(\"\\n\")\n",
    "print(\"Accuracy \", aAccuracy[0].mean())\n",
    "print(\"Precision \", aPrecision[0].mean())\n",
    "print(\"Recall \", aRecall[0].mean())\n",
    "print(\"F1 \", aF1[0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp; 3-B. Multi-Layer Perceptron (Canonical Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Methods 10th-Mean values for MLP\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Accuracy  0.7871328671328671\n",
      "Precision  0.7712221341849673\n",
      "Recall  0.7853839338765809\n",
      "F1  0.7664053795818214\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train, test in kf.split(df0):\n",
    "    y_train = df0.iloc[train][df0.columns[-1]]\n",
    "    x_train = df0.iloc[train].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    y_test = df0.iloc[test][df0.columns[-1]]\n",
    "    x_test = df0.iloc[test].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1224, max_iter = 200)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    predicted = clf.predict(x_test)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test.values, predicted).ravel()    \n",
    "    \n",
    "    Accuracy  = (TP+TN)/(TP+TN+FP+FN)\n",
    "    Precision = (TP)/(TP+FP)\n",
    "    Recall = (TP)/(TP+FN)\n",
    "    F1 = (2*Precision*Recall)/(Precision + Recall)\n",
    "    \n",
    "    aAccuracy[0][i] = Accuracy\n",
    "    aPrecision[0][i] = Precision\n",
    "    aRecall[0][i] = Recall\n",
    "    aF1[0][i] = F1\n",
    "\n",
    "    i = i + 1    \n",
    "    report = classification_report(y_test.values, predicted)\n",
    "\n",
    "i = 0    \n",
    "print(\"Evaluation Methods 10th-Mean values for MLP\")    \n",
    "print(\"-\"*50)    \n",
    "print(\"\\n\")\n",
    "print(\"Accuracy \", aAccuracy[0].mean())\n",
    "print(\"Precision \", aPrecision[0].mean())\n",
    "print(\"Recall \", aRecall[0].mean())\n",
    "print(\"F1 \", aF1[0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp; 3-C. Random Forest (Committe Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Methods 10th-Mean values for Random Forest\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Accuracy  0.8651748251748252\n",
      "Precision  0.8426477100595882\n",
      "Recall  0.8687149329428742\n",
      "F1  0.849916387411534\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train, test in kf.split(df0):\n",
    "#     print(\"%s %s\" % (train, test))\n",
    "    y_train = df0.iloc[train][df0.columns[-1]]\n",
    "    x_train = df0.iloc[train].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    y_test = df0.iloc[test][df0.columns[-1]]\n",
    "    x_test = df0.iloc[test].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=500,\n",
    "                                criterion='gini',\n",
    "                                max_depth=5,\n",
    "                                min_samples_split=2,\n",
    "                                random_state=1224)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "    \n",
    "    TN, FP, FN, TP = confusion_matrix(y_test.values, predicted).ravel()    \n",
    "\n",
    "    Accuracy  = (TP+TN)/(TP+TN+FP+FN)\n",
    "    Precision = (TP)/(TP+FP)\n",
    "    Recall = (TP)/(TP+FN)\n",
    "    F1 = (2*Precision*Recall)/(Precision + Recall)\n",
    "    \n",
    "    aAccuracy[0][i] = Accuracy\n",
    "    aPrecision[0][i] = Precision\n",
    "    aRecall[0][i] = Recall\n",
    "    aF1[0][i] = F1\n",
    "\n",
    "    i = i + 1    \n",
    "    report = classification_report(y_test.values, predicted)\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "print(\"Evaluation Methods 10th-Mean values for Random Forest\")    \n",
    "print(\"-\"*50)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy \", aAccuracy[0].mean())\n",
    "print(\"Precision \", aPrecision[0].mean())\n",
    "print(\"Recall \", aRecall[0].mean())\n",
    "print(\"F1 \", aF1[0].mean())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp; 3-D. Adaboost (Committe Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Methods 10th-Mean values\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Accuracy  0.8667599067599067\n",
      "Precision  0.813082746261278\n",
      "Recall  0.9256242219109865\n",
      "F1  0.8613637700667324\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train, test in kf.split(df0):\n",
    "#     print(\"%s %s\" % (train, test))\n",
    "    y_train = df0.iloc[train][df0.columns[-1]]\n",
    "    x_train = df0.iloc[train].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    y_test = df0.iloc[test][df0.columns[-1]]\n",
    "    x_test = df0.iloc[test].drop(df0.columns[-1], axis=1)\n",
    "\n",
    "    clf =  AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                              n_estimators=10,\n",
    "                              learning_rate=0.5)\n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "    \n",
    "    TN, FP, FN, TP = confusion_matrix(y_test.values, predicted).ravel()    \n",
    "\n",
    "    Accuracy  = (TP+TN)/(TP+TN+FP+FN)\n",
    "    Precision = (TP)/(TP+FP)\n",
    "    Recall = (TP)/(TP+FN)\n",
    "    F1 = (2*Precision*Recall)/(Precision + Recall)\n",
    "    \n",
    "    aAccuracy[0][i] = Accuracy\n",
    "    aPrecision[0][i] = Precision\n",
    "    aRecall[0][i] = Recall\n",
    "    aF1[0][i] = F1\n",
    "\n",
    "    i = i + 1    \n",
    "    report = classification_report(y_test.values, predicted)\n",
    "\n",
    "i = 0\n",
    "print(\"Evaluation Methods 10th-Mean values\")    \n",
    "print(\"-\"*50)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy \", aAccuracy[0].mean())\n",
    "print(\"Precision \", aPrecision[0].mean())\n",
    "print(\"Recall \", aRecall[0].mean())\n",
    "print(\"F1 \", aF1[0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp; 3-E. CNN (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "587/587 [==============================] - 2s 4ms/step - loss: 0.6575 - acc: 0.5877\n",
      "Epoch 2/100\n",
      "587/587 [==============================] - 0s 509us/step - loss: 0.6524 - acc: 0.6729\n",
      "Epoch 3/100\n",
      "587/587 [==============================] - 0s 453us/step - loss: 0.6485 - acc: 0.6712 0s - loss: 0.6543 - acc: 0.6\n",
      "Epoch 4/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.6507 - acc: 0.6576\n",
      "Epoch 5/100\n",
      "587/587 [==============================] - 0s 430us/step - loss: 0.6452 - acc: 0.6695\n",
      "Epoch 6/100\n",
      "587/587 [==============================] - 0s 460us/step - loss: 0.6447 - acc: 0.6763\n",
      "Epoch 7/100\n",
      "587/587 [==============================] - 0s 504us/step - loss: 0.6400 - acc: 0.6661\n",
      "Epoch 8/100\n",
      "587/587 [==============================] - 0s 537us/step - loss: 0.6435 - acc: 0.6695\n",
      "Epoch 9/100\n",
      "587/587 [==============================] - 0s 510us/step - loss: 0.6407 - acc: 0.6610\n",
      "Epoch 10/100\n",
      "587/587 [==============================] - 0s 532us/step - loss: 0.6393 - acc: 0.6695\n",
      "Epoch 11/100\n",
      "587/587 [==============================] - 0s 544us/step - loss: 0.6338 - acc: 0.6729\n",
      "Epoch 12/100\n",
      "587/587 [==============================] - 0s 563us/step - loss: 0.6428 - acc: 0.6934\n",
      "Epoch 13/100\n",
      "587/587 [==============================] - 0s 521us/step - loss: 0.6309 - acc: 0.6780\n",
      "Epoch 14/100\n",
      "587/587 [==============================] - 0s 467us/step - loss: 0.6269 - acc: 0.6797\n",
      "Epoch 15/100\n",
      "587/587 [==============================] - ETA: 0s - loss: 0.6156 - acc: 0.692 - 0s 495us/step - loss: 0.6224 - acc: 0.6917\n",
      "Epoch 16/100\n",
      "587/587 [==============================] - 0s 522us/step - loss: 0.6163 - acc: 0.7036\n",
      "Epoch 17/100\n",
      "587/587 [==============================] - 0s 496us/step - loss: 0.6113 - acc: 0.7172\n",
      "Epoch 18/100\n",
      "587/587 [==============================] - 0s 562us/step - loss: 0.6078 - acc: 0.7240\n",
      "Epoch 19/100\n",
      "587/587 [==============================] - 0s 482us/step - loss: 0.5868 - acc: 0.7922\n",
      "Epoch 20/100\n",
      "587/587 [==============================] - 0s 488us/step - loss: 0.5674 - acc: 0.7871\n",
      "Epoch 21/100\n",
      "587/587 [==============================] - 0s 460us/step - loss: 0.5493 - acc: 0.8177\n",
      "Epoch 22/100\n",
      "587/587 [==============================] - 0s 510us/step - loss: 0.5316 - acc: 0.8024\n",
      "Epoch 23/100\n",
      "587/587 [==============================] - 0s 491us/step - loss: 0.5115 - acc: 0.8211\n",
      "Epoch 24/100\n",
      "587/587 [==============================] - 0s 443us/step - loss: 0.4981 - acc: 0.8433\n",
      "Epoch 25/100\n",
      "587/587 [==============================] - 0s 464us/step - loss: 0.4862 - acc: 0.8330\n",
      "Epoch 26/100\n",
      "587/587 [==============================] - 0s 472us/step - loss: 0.4842 - acc: 0.8296\n",
      "Epoch 27/100\n",
      "587/587 [==============================] - 0s 497us/step - loss: 0.4580 - acc: 0.8535\n",
      "Epoch 28/100\n",
      "587/587 [==============================] - 0s 479us/step - loss: 0.4511 - acc: 0.8433\n",
      "Epoch 29/100\n",
      "587/587 [==============================] - 0s 479us/step - loss: 0.4469 - acc: 0.8501\n",
      "Epoch 30/100\n",
      "587/587 [==============================] - 0s 506us/step - loss: 0.4340 - acc: 0.8552\n",
      "Epoch 31/100\n",
      "587/587 [==============================] - 0s 469us/step - loss: 0.4250 - acc: 0.8586\n",
      "Epoch 32/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.4351 - acc: 0.8603\n",
      "Epoch 33/100\n",
      "587/587 [==============================] - 0s 448us/step - loss: 0.4098 - acc: 0.8569\n",
      "Epoch 34/100\n",
      "587/587 [==============================] - 0s 430us/step - loss: 0.4054 - acc: 0.8705\n",
      "Epoch 35/100\n",
      "587/587 [==============================] - 0s 432us/step - loss: 0.4025 - acc: 0.8552\n",
      "Epoch 36/100\n",
      "587/587 [==============================] - 0s 424us/step - loss: 0.3952 - acc: 0.8637\n",
      "Epoch 37/100\n",
      "587/587 [==============================] - 0s 479us/step - loss: 0.3955 - acc: 0.8671\n",
      "Epoch 38/100\n",
      "587/587 [==============================] - 0s 532us/step - loss: 0.3949 - acc: 0.8603 0s - loss: 0.4081 - acc: 0.8\n",
      "Epoch 39/100\n",
      "587/587 [==============================] - 0s 518us/step - loss: 0.3866 - acc: 0.8654\n",
      "Epoch 40/100\n",
      "587/587 [==============================] - 0s 518us/step - loss: 0.3781 - acc: 0.8688\n",
      "Epoch 41/100\n",
      "587/587 [==============================] - 0s 508us/step - loss: 0.3744 - acc: 0.8688\n",
      "Epoch 42/100\n",
      "587/587 [==============================] - 0s 517us/step - loss: 0.3804 - acc: 0.8654\n",
      "Epoch 43/100\n",
      "587/587 [==============================] - 0s 517us/step - loss: 0.3709 - acc: 0.8722\n",
      "Epoch 44/100\n",
      "587/587 [==============================] - 0s 417us/step - loss: 0.3751 - acc: 0.8671\n",
      "Epoch 45/100\n",
      "587/587 [==============================] - 0s 466us/step - loss: 0.3653 - acc: 0.8671\n",
      "Epoch 46/100\n",
      "587/587 [==============================] - 0s 439us/step - loss: 0.3589 - acc: 0.8705\n",
      "Epoch 47/100\n",
      "587/587 [==============================] - 0s 426us/step - loss: 0.3556 - acc: 0.8773\n",
      "Epoch 48/100\n",
      "587/587 [==============================] - 0s 417us/step - loss: 0.3536 - acc: 0.8807\n",
      "Epoch 49/100\n",
      "587/587 [==============================] - 0s 430us/step - loss: 0.3551 - acc: 0.8756\n",
      "Epoch 50/100\n",
      "587/587 [==============================] - 0s 455us/step - loss: 0.3626 - acc: 0.8654\n",
      "Epoch 51/100\n",
      "587/587 [==============================] - 0s 419us/step - loss: 0.3519 - acc: 0.8705\n",
      "Epoch 52/100\n",
      "587/587 [==============================] - 0s 441us/step - loss: 0.3441 - acc: 0.8876\n",
      "Epoch 53/100\n",
      "587/587 [==============================] - 0s 461us/step - loss: 0.3477 - acc: 0.8807\n",
      "Epoch 54/100\n",
      "587/587 [==============================] - 0s 434us/step - loss: 0.3424 - acc: 0.8773\n",
      "Epoch 55/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.3383 - acc: 0.8842\n",
      "Epoch 56/100\n",
      "587/587 [==============================] - 0s 431us/step - loss: 0.3357 - acc: 0.8756\n",
      "Epoch 57/100\n",
      "587/587 [==============================] - 0s 433us/step - loss: 0.3390 - acc: 0.8705\n",
      "Epoch 58/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.3361 - acc: 0.8739\n",
      "Epoch 59/100\n",
      "587/587 [==============================] - 0s 436us/step - loss: 0.3302 - acc: 0.8825\n",
      "Epoch 60/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.3282 - acc: 0.8722\n",
      "Epoch 61/100\n",
      "587/587 [==============================] - 0s 495us/step - loss: 0.3320 - acc: 0.8722\n",
      "Epoch 62/100\n",
      "587/587 [==============================] - 0s 470us/step - loss: 0.3295 - acc: 0.8671\n",
      "Epoch 63/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.3343 - acc: 0.8739\n",
      "Epoch 64/100\n",
      "587/587 [==============================] - 0s 437us/step - loss: 0.3219 - acc: 0.8807\n",
      "Epoch 65/100\n",
      "587/587 [==============================] - 0s 496us/step - loss: 0.3218 - acc: 0.8825\n",
      "Epoch 66/100\n",
      "587/587 [==============================] - 0s 439us/step - loss: 0.3291 - acc: 0.8671\n",
      "Epoch 67/100\n",
      "587/587 [==============================] - 0s 422us/step - loss: 0.3213 - acc: 0.8756\n",
      "Epoch 68/100\n",
      "587/587 [==============================] - 0s 463us/step - loss: 0.3190 - acc: 0.8825\n",
      "Epoch 69/100\n",
      "587/587 [==============================] - 0s 445us/step - loss: 0.3226 - acc: 0.8825\n",
      "Epoch 70/100\n",
      "587/587 [==============================] - 0s 438us/step - loss: 0.3134 - acc: 0.8893\n",
      "Epoch 71/100\n",
      "587/587 [==============================] - 0s 501us/step - loss: 0.3172 - acc: 0.8773\n",
      "Epoch 72/100\n",
      "587/587 [==============================] - 0s 540us/step - loss: 0.3095 - acc: 0.8790\n",
      "Epoch 73/100\n",
      "587/587 [==============================] - 0s 515us/step - loss: 0.3118 - acc: 0.8807\n",
      "Epoch 74/100\n",
      "587/587 [==============================] - 0s 472us/step - loss: 0.3152 - acc: 0.8739\n",
      "Epoch 75/100\n",
      "587/587 [==============================] - 0s 499us/step - loss: 0.3101 - acc: 0.8842\n",
      "Epoch 76/100\n",
      "587/587 [==============================] - 0s 488us/step - loss: 0.3147 - acc: 0.8756\n",
      "Epoch 77/100\n",
      "587/587 [==============================] - 0s 473us/step - loss: 0.3136 - acc: 0.8876\n",
      "Epoch 78/100\n",
      "587/587 [==============================] - 0s 493us/step - loss: 0.3130 - acc: 0.8773\n",
      "Epoch 79/100\n",
      "587/587 [==============================] - 0s 499us/step - loss: 0.3050 - acc: 0.8893\n",
      "Epoch 80/100\n",
      "587/587 [==============================] - 0s 477us/step - loss: 0.3171 - acc: 0.8842\n",
      "Epoch 81/100\n",
      "587/587 [==============================] - 0s 481us/step - loss: 0.3075 - acc: 0.8876\n",
      "Epoch 82/100\n",
      "587/587 [==============================] - 0s 505us/step - loss: 0.3023 - acc: 0.8807 0s - loss: 0.3391 - acc: 0\n",
      "Epoch 83/100\n",
      "587/587 [==============================] - 0s 530us/step - loss: 0.3026 - acc: 0.8790\n",
      "Epoch 84/100\n",
      "587/587 [==============================] - 0s 499us/step - loss: 0.3020 - acc: 0.8859\n",
      "Epoch 85/100\n",
      "587/587 [==============================] - 0s 466us/step - loss: 0.3045 - acc: 0.8790\n",
      "Epoch 86/100\n",
      "587/587 [==============================] - 0s 459us/step - loss: 0.3000 - acc: 0.8825\n",
      "Epoch 87/100\n",
      "587/587 [==============================] - 0s 498us/step - loss: 0.2987 - acc: 0.8790\n",
      "Epoch 88/100\n",
      "587/587 [==============================] - 0s 502us/step - loss: 0.3091 - acc: 0.8739\n",
      "Epoch 89/100\n",
      "587/587 [==============================] - 0s 456us/step - loss: 0.3117 - acc: 0.8739\n",
      "Epoch 90/100\n",
      "587/587 [==============================] - 0s 451us/step - loss: 0.3075 - acc: 0.8859\n",
      "Epoch 91/100\n",
      "587/587 [==============================] - 0s 460us/step - loss: 0.3001 - acc: 0.8825\n",
      "Epoch 92/100\n",
      "587/587 [==============================] - 0s 426us/step - loss: 0.2979 - acc: 0.8910\n",
      "Epoch 93/100\n",
      "587/587 [==============================] - 0s 445us/step - loss: 0.2987 - acc: 0.8756\n",
      "Epoch 94/100\n",
      "587/587 [==============================] - 0s 460us/step - loss: 0.2957 - acc: 0.8893\n",
      "Epoch 95/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.3098 - acc: 0.8807\n",
      "Epoch 96/100\n",
      "587/587 [==============================] - 0s 417us/step - loss: 0.2966 - acc: 0.8807\n",
      "Epoch 97/100\n",
      "587/587 [==============================] - 0s 436us/step - loss: 0.2946 - acc: 0.8807\n",
      "Epoch 98/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.3077 - acc: 0.8825\n",
      "Epoch 99/100\n",
      "587/587 [==============================] - 0s 433us/step - loss: 0.2893 - acc: 0.8893\n",
      "Epoch 100/100\n",
      "587/587 [==============================] - 0s 426us/step - loss: 0.2927 - acc: 0.8876\n",
      "66/66 [==============================] - 1s 12ms/step\n",
      "acc: 95.45%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "587/587 [==============================] - 2s 4ms/step - loss: 0.6792 - acc: 0.5417\n",
      "Epoch 2/100\n",
      "587/587 [==============================] - 0s 441us/step - loss: 0.6636 - acc: 0.5503\n",
      "Epoch 3/100\n",
      "587/587 [==============================] - 0s 439us/step - loss: 0.6586 - acc: 0.6286\n",
      "Epoch 4/100\n",
      "587/587 [==============================] - 0s 430us/step - loss: 0.6575 - acc: 0.6848\n",
      "Epoch 5/100\n",
      "587/587 [==============================] - 0s 441us/step - loss: 0.6574 - acc: 0.6814\n",
      "Epoch 6/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.6511 - acc: 0.6763\n",
      "Epoch 7/100\n",
      "587/587 [==============================] - 0s 444us/step - loss: 0.6495 - acc: 0.6934\n",
      "Epoch 8/100\n",
      "587/587 [==============================] - 0s 444us/step - loss: 0.6463 - acc: 0.6797\n",
      "Epoch 9/100\n",
      "587/587 [==============================] - 0s 463us/step - loss: 0.6383 - acc: 0.6985\n",
      "Epoch 10/100\n",
      "587/587 [==============================] - 0s 447us/step - loss: 0.6372 - acc: 0.7070 0s - loss: 0.6430 - acc: 0.70\n",
      "Epoch 11/100\n",
      "587/587 [==============================] - 0s 427us/step - loss: 0.6307 - acc: 0.7019\n",
      "Epoch 12/100\n",
      "587/587 [==============================] - 0s 466us/step - loss: 0.6223 - acc: 0.6968\n",
      "Epoch 13/100\n",
      "587/587 [==============================] - 0s 471us/step - loss: 0.6192 - acc: 0.7053\n",
      "Epoch 14/100\n",
      "587/587 [==============================] - 0s 529us/step - loss: 0.6081 - acc: 0.7019\n",
      "Epoch 15/100\n",
      "587/587 [==============================] - 0s 500us/step - loss: 0.6061 - acc: 0.7155\n",
      "Epoch 16/100\n",
      "587/587 [==============================] - 0s 521us/step - loss: 0.5888 - acc: 0.7121\n",
      "Epoch 17/100\n",
      "587/587 [==============================] - 0s 486us/step - loss: 0.5754 - acc: 0.7325\n",
      "Epoch 18/100\n",
      "587/587 [==============================] - 0s 518us/step - loss: 0.5625 - acc: 0.7445\n",
      "Epoch 19/100\n",
      "587/587 [==============================] - 0s 493us/step - loss: 0.5442 - acc: 0.7445\n",
      "Epoch 20/100\n",
      "587/587 [==============================] - 0s 489us/step - loss: 0.5198 - acc: 0.7734\n",
      "Epoch 21/100\n",
      "587/587 [==============================] - 0s 510us/step - loss: 0.4967 - acc: 0.8075\n",
      "Epoch 22/100\n",
      "587/587 [==============================] - 0s 452us/step - loss: 0.5430 - acc: 0.7853\n",
      "Epoch 23/100\n",
      "587/587 [==============================] - 0s 480us/step - loss: 0.5517 - acc: 0.7070\n",
      "Epoch 24/100\n",
      "587/587 [==============================] - 0s 484us/step - loss: 0.4937 - acc: 0.7819\n",
      "Epoch 25/100\n",
      "587/587 [==============================] - 0s 484us/step - loss: 0.4883 - acc: 0.7905\n",
      "Epoch 26/100\n",
      "587/587 [==============================] - 0s 488us/step - loss: 0.4817 - acc: 0.7939\n",
      "Epoch 27/100\n",
      "587/587 [==============================] - 0s 453us/step - loss: 0.4739 - acc: 0.7888\n",
      "Epoch 28/100\n",
      "587/587 [==============================] - 0s 488us/step - loss: 0.4599 - acc: 0.7973\n",
      "Epoch 29/100\n",
      "587/587 [==============================] - 0s 506us/step - loss: 0.4624 - acc: 0.8177\n",
      "Epoch 30/100\n",
      "587/587 [==============================] - 0s 459us/step - loss: 0.4492 - acc: 0.8211\n",
      "Epoch 31/100\n",
      "587/587 [==============================] - 0s 435us/step - loss: 0.4312 - acc: 0.8484\n",
      "Epoch 32/100\n",
      "587/587 [==============================] - 0s 447us/step - loss: 0.4314 - acc: 0.8330\n",
      "Epoch 33/100\n",
      "587/587 [==============================] - 0s 466us/step - loss: 0.4124 - acc: 0.8569\n",
      "Epoch 34/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.4043 - acc: 0.8569\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587/587 [==============================] - 0s 455us/step - loss: 0.3964 - acc: 0.8722\n",
      "Epoch 36/100\n",
      "587/587 [==============================] - 0s 439us/step - loss: 0.3899 - acc: 0.8603\n",
      "Epoch 37/100\n",
      "587/587 [==============================] - 0s 438us/step - loss: 0.3987 - acc: 0.8654\n",
      "Epoch 38/100\n",
      "587/587 [==============================] - 0s 435us/step - loss: 0.3744 - acc: 0.8756\n",
      "Epoch 39/100\n",
      "587/587 [==============================] - 0s 433us/step - loss: 0.3792 - acc: 0.8739\n",
      "Epoch 40/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.3735 - acc: 0.8756\n",
      "Epoch 41/100\n",
      "587/587 [==============================] - 0s 446us/step - loss: 0.3717 - acc: 0.8722\n",
      "Epoch 42/100\n",
      "587/587 [==============================] - 0s 441us/step - loss: 0.3717 - acc: 0.8620\n",
      "Epoch 43/100\n",
      "587/587 [==============================] - 0s 445us/step - loss: 0.3702 - acc: 0.8722\n",
      "Epoch 44/100\n",
      "587/587 [==============================] - 0s 468us/step - loss: 0.3781 - acc: 0.8654\n",
      "Epoch 45/100\n",
      "587/587 [==============================] - 0s 449us/step - loss: 0.3677 - acc: 0.8773\n",
      "Epoch 46/100\n",
      "587/587 [==============================] - 0s 435us/step - loss: 0.3646 - acc: 0.8671\n",
      "Epoch 47/100\n",
      "587/587 [==============================] - 0s 471us/step - loss: 0.3723 - acc: 0.8773\n",
      "Epoch 48/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.3558 - acc: 0.8807\n",
      "Epoch 49/100\n",
      "587/587 [==============================] - 0s 466us/step - loss: 0.3514 - acc: 0.8825\n",
      "Epoch 50/100\n",
      "587/587 [==============================] - 0s 443us/step - loss: 0.3524 - acc: 0.8756\n",
      "Epoch 51/100\n",
      "587/587 [==============================] - 0s 434us/step - loss: 0.3704 - acc: 0.8654\n",
      "Epoch 52/100\n",
      "587/587 [==============================] - 0s 458us/step - loss: 0.3629 - acc: 0.8756\n",
      "Epoch 53/100\n",
      "587/587 [==============================] - 0s 451us/step - loss: 0.3678 - acc: 0.8654\n",
      "Epoch 54/100\n",
      "587/587 [==============================] - 0s 438us/step - loss: 0.3599 - acc: 0.8722\n",
      "Epoch 55/100\n",
      "587/587 [==============================] - 0s 452us/step - loss: 0.3451 - acc: 0.8671\n",
      "Epoch 56/100\n",
      "587/587 [==============================] - 0s 461us/step - loss: 0.3467 - acc: 0.8654\n",
      "Epoch 57/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.3371 - acc: 0.8773\n",
      "Epoch 58/100\n",
      "587/587 [==============================] - 0s 435us/step - loss: 0.3411 - acc: 0.8756\n",
      "Epoch 59/100\n",
      "587/587 [==============================] - 0s 464us/step - loss: 0.3363 - acc: 0.8790\n",
      "Epoch 60/100\n",
      "587/587 [==============================] - 0s 425us/step - loss: 0.3406 - acc: 0.8842\n",
      "Epoch 61/100\n",
      "587/587 [==============================] - 0s 438us/step - loss: 0.3377 - acc: 0.8773\n",
      "Epoch 62/100\n",
      "587/587 [==============================] - 0s 481us/step - loss: 0.3331 - acc: 0.8859\n",
      "Epoch 63/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.3406 - acc: 0.8739\n",
      "Epoch 64/100\n",
      "587/587 [==============================] - 0s 467us/step - loss: 0.3300 - acc: 0.8722\n",
      "Epoch 65/100\n",
      "587/587 [==============================] - 0s 430us/step - loss: 0.3267 - acc: 0.8893\n",
      "Epoch 66/100\n",
      "587/587 [==============================] - 0s 435us/step - loss: 0.3336 - acc: 0.8790\n",
      "Epoch 67/100\n",
      "587/587 [==============================] - 0s 471us/step - loss: 0.3234 - acc: 0.8756\n",
      "Epoch 68/100\n",
      "587/587 [==============================] - 0s 459us/step - loss: 0.3315 - acc: 0.8825\n",
      "Epoch 69/100\n",
      "587/587 [==============================] - 0s 457us/step - loss: 0.3427 - acc: 0.8739\n",
      "Epoch 70/100\n",
      "587/587 [==============================] - 0s 504us/step - loss: 0.3340 - acc: 0.8705\n",
      "Epoch 71/100\n",
      "587/587 [==============================] - 0s 445us/step - loss: 0.3242 - acc: 0.8842\n",
      "Epoch 72/100\n",
      "587/587 [==============================] - 0s 486us/step - loss: 0.3207 - acc: 0.8842\n",
      "Epoch 73/100\n",
      "587/587 [==============================] - 0s 513us/step - loss: 0.3238 - acc: 0.8790\n",
      "Epoch 74/100\n",
      "587/587 [==============================] - 0s 493us/step - loss: 0.3199 - acc: 0.8773\n",
      "Epoch 75/100\n",
      "587/587 [==============================] - 0s 511us/step - loss: 0.3141 - acc: 0.8910\n",
      "Epoch 76/100\n",
      "587/587 [==============================] - 0s 522us/step - loss: 0.3142 - acc: 0.8790\n",
      "Epoch 77/100\n",
      "587/587 [==============================] - 0s 477us/step - loss: 0.3177 - acc: 0.8825\n",
      "Epoch 78/100\n",
      "587/587 [==============================] - 0s 476us/step - loss: 0.3036 - acc: 0.8961 0s - loss: 0.2779 - acc: 0\n",
      "Epoch 79/100\n",
      "587/587 [==============================] - 0s 498us/step - loss: 0.3164 - acc: 0.8893\n",
      "Epoch 80/100\n",
      "587/587 [==============================] - ETA: 0s - loss: 0.3053 - acc: 0.883 - 0s 497us/step - loss: 0.3082 - acc: 0.8842\n",
      "Epoch 81/100\n",
      "587/587 [==============================] - 0s 488us/step - loss: 0.3155 - acc: 0.8807\n",
      "Epoch 82/100\n",
      "587/587 [==============================] - 0s 473us/step - loss: 0.3065 - acc: 0.8944\n",
      "Epoch 83/100\n",
      "587/587 [==============================] - 0s 488us/step - loss: 0.3065 - acc: 0.8944\n",
      "Epoch 84/100\n",
      "587/587 [==============================] - 0s 454us/step - loss: 0.3053 - acc: 0.8927\n",
      "Epoch 85/100\n",
      "587/587 [==============================] - 0s 525us/step - loss: 0.3047 - acc: 0.8910\n",
      "Epoch 86/100\n",
      "587/587 [==============================] - 0s 499us/step - loss: 0.3061 - acc: 0.8790\n",
      "Epoch 87/100\n",
      "587/587 [==============================] - 0s 449us/step - loss: 0.3022 - acc: 0.8876\n",
      "Epoch 88/100\n",
      "587/587 [==============================] - 0s 537us/step - loss: 0.3021 - acc: 0.8825\n",
      "Epoch 89/100\n",
      "587/587 [==============================] - 0s 469us/step - loss: 0.3027 - acc: 0.8859\n",
      "Epoch 90/100\n",
      "587/587 [==============================] - 0s 437us/step - loss: 0.3301 - acc: 0.8705\n",
      "Epoch 91/100\n",
      "587/587 [==============================] - 0s 476us/step - loss: 0.3398 - acc: 0.8722\n",
      "Epoch 92/100\n",
      "587/587 [==============================] - 0s 453us/step - loss: 0.3014 - acc: 0.8944\n",
      "Epoch 93/100\n",
      "587/587 [==============================] - 0s 455us/step - loss: 0.3013 - acc: 0.8859\n",
      "Epoch 94/100\n",
      "587/587 [==============================] - 0s 463us/step - loss: 0.2988 - acc: 0.8876\n",
      "Epoch 95/100\n",
      "587/587 [==============================] - 0s 430us/step - loss: 0.2969 - acc: 0.8910\n",
      "Epoch 96/100\n",
      "587/587 [==============================] - 0s 449us/step - loss: 0.3042 - acc: 0.8961\n",
      "Epoch 97/100\n",
      "587/587 [==============================] - 0s 442us/step - loss: 0.3199 - acc: 0.8739\n",
      "Epoch 98/100\n",
      "587/587 [==============================] - 0s 456us/step - loss: 0.3050 - acc: 0.8825\n",
      "Epoch 99/100\n",
      "587/587 [==============================] - 0s 441us/step - loss: 0.3018 - acc: 0.8825\n",
      "Epoch 100/100\n",
      "587/587 [==============================] - 0s 425us/step - loss: 0.2965 - acc: 0.8876\n",
      "66/66 [==============================] - 1s 12ms/step\n",
      "acc: 86.36%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "587/587 [==============================] - 2s 4ms/step - loss: 0.6588 - acc: 0.5656\n",
      "Epoch 2/100\n",
      "587/587 [==============================] - 0s 471us/step - loss: 0.6501 - acc: 0.6814\n",
      "Epoch 3/100\n",
      "587/587 [==============================] - 0s 484us/step - loss: 0.6502 - acc: 0.6917\n",
      "Epoch 4/100\n",
      "587/587 [==============================] - 0s 466us/step - loss: 0.6452 - acc: 0.6951\n",
      "Epoch 5/100\n",
      "587/587 [==============================] - ETA: 0s - loss: 0.6393 - acc: 0.700 - 0s 493us/step - loss: 0.6433 - acc: 0.6951\n",
      "Epoch 6/100\n",
      "587/587 [==============================] - 0s 540us/step - loss: 0.6379 - acc: 0.7070\n",
      "Epoch 7/100\n",
      "587/587 [==============================] - 0s 493us/step - loss: 0.6338 - acc: 0.6968\n",
      "Epoch 8/100\n",
      "587/587 [==============================] - 0s 491us/step - loss: 0.6341 - acc: 0.7002\n",
      "Epoch 9/100\n",
      "587/587 [==============================] - 0s 480us/step - loss: 0.6319 - acc: 0.6934\n",
      "Epoch 10/100\n",
      "587/587 [==============================] - 0s 468us/step - loss: 0.6260 - acc: 0.6865\n",
      "Epoch 11/100\n",
      "587/587 [==============================] - 0s 433us/step - loss: 0.6269 - acc: 0.6951\n",
      "Epoch 12/100\n",
      "587/587 [==============================] - 0s 484us/step - loss: 0.6322 - acc: 0.6831\n",
      "Epoch 13/100\n",
      "587/587 [==============================] - 0s 550us/step - loss: 0.6208 - acc: 0.6899\n",
      "Epoch 14/100\n",
      "587/587 [==============================] - 0s 597us/step - loss: 0.6222 - acc: 0.6882\n",
      "Epoch 15/100\n",
      "587/587 [==============================] - 0s 599us/step - loss: 0.6164 - acc: 0.6917\n",
      "Epoch 16/100\n",
      "587/587 [==============================] - 0s 592us/step - loss: 0.6186 - acc: 0.6934\n",
      "Epoch 17/100\n",
      "587/587 [==============================] - 0s 560us/step - loss: 0.6113 - acc: 0.6899\n",
      "Epoch 18/100\n",
      "587/587 [==============================] - 0s 571us/step - loss: 0.6117 - acc: 0.6882\n",
      "Epoch 19/100\n",
      "587/587 [==============================] - 0s 554us/step - loss: 0.6102 - acc: 0.7002\n",
      "Epoch 20/100\n",
      "587/587 [==============================] - 0s 546us/step - loss: 0.6020 - acc: 0.7087\n",
      "Epoch 21/100\n",
      "587/587 [==============================] - 0s 609us/step - loss: 0.5903 - acc: 0.7206\n",
      "Epoch 22/100\n",
      "587/587 [==============================] - 0s 552us/step - loss: 0.6048 - acc: 0.7172\n",
      "Epoch 23/100\n",
      "587/587 [==============================] - 0s 550us/step - loss: 0.6017 - acc: 0.7206\n",
      "Epoch 24/100\n",
      "587/587 [==============================] - 0s 527us/step - loss: 0.5883 - acc: 0.7342\n",
      "Epoch 25/100\n",
      "587/587 [==============================] - 0s 522us/step - loss: 0.5834 - acc: 0.7206\n",
      "Epoch 26/100\n",
      "587/587 [==============================] - 0s 579us/step - loss: 0.5862 - acc: 0.7104\n",
      "Epoch 27/100\n",
      "587/587 [==============================] - 0s 581us/step - loss: 0.5799 - acc: 0.7240\n",
      "Epoch 28/100\n",
      "587/587 [==============================] - 0s 609us/step - loss: 0.5814 - acc: 0.7087 0s - loss: 0.5926 - acc: 0\n",
      "Epoch 29/100\n",
      "587/587 [==============================] - 0s 615us/step - loss: 0.5730 - acc: 0.7189\n",
      "Epoch 30/100\n",
      "587/587 [==============================] - 0s 586us/step - loss: 0.5697 - acc: 0.7206\n",
      "Epoch 31/100\n",
      "587/587 [==============================] - 0s 569us/step - loss: 0.5624 - acc: 0.7274\n",
      "Epoch 32/100\n",
      "587/587 [==============================] - 0s 523us/step - loss: 0.5658 - acc: 0.7257\n",
      "Epoch 33/100\n",
      "587/587 [==============================] - 0s 473us/step - loss: 0.5550 - acc: 0.7359\n",
      "Epoch 34/100\n",
      "587/587 [==============================] - 0s 467us/step - loss: 0.5611 - acc: 0.7394\n",
      "Epoch 35/100\n",
      "587/587 [==============================] - 0s 488us/step - loss: 0.5481 - acc: 0.7445\n",
      "Epoch 36/100\n",
      "587/587 [==============================] - 0s 477us/step - loss: 0.5430 - acc: 0.7479\n",
      "Epoch 37/100\n",
      "587/587 [==============================] - 0s 472us/step - loss: 0.5424 - acc: 0.7394\n",
      "Epoch 38/100\n",
      "587/587 [==============================] - 0s 500us/step - loss: 0.5398 - acc: 0.7479\n",
      "Epoch 39/100\n",
      "587/587 [==============================] - 0s 498us/step - loss: 0.5309 - acc: 0.7547\n",
      "Epoch 40/100\n",
      "587/587 [==============================] - 0s 510us/step - loss: 0.5259 - acc: 0.7598\n",
      "Epoch 41/100\n",
      "587/587 [==============================] - 0s 474us/step - loss: 0.5163 - acc: 0.7683\n",
      "Epoch 42/100\n",
      "587/587 [==============================] - 0s 484us/step - loss: 0.5130 - acc: 0.7513\n",
      "Epoch 43/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.5056 - acc: 0.7751\n",
      "Epoch 44/100\n",
      "587/587 [==============================] - 0s 466us/step - loss: 0.4994 - acc: 0.7853\n",
      "Epoch 45/100\n",
      "587/587 [==============================] - 0s 499us/step - loss: 0.4909 - acc: 0.7871 0s - loss: 0.5448 - acc: 0\n",
      "Epoch 46/100\n",
      "587/587 [==============================] - 0s 499us/step - loss: 0.4804 - acc: 0.7853\n",
      "Epoch 47/100\n",
      "587/587 [==============================] - 0s 468us/step - loss: 0.4812 - acc: 0.7939\n",
      "Epoch 48/100\n",
      "587/587 [==============================] - 0s 439us/step - loss: 0.4623 - acc: 0.8126\n",
      "Epoch 49/100\n",
      "587/587 [==============================] - 0s 498us/step - loss: 0.4552 - acc: 0.8075\n",
      "Epoch 50/100\n",
      "587/587 [==============================] - 0s 439us/step - loss: 0.4511 - acc: 0.8228\n",
      "Epoch 51/100\n",
      "587/587 [==============================] - 0s 438us/step - loss: 0.4382 - acc: 0.8348\n",
      "Epoch 52/100\n",
      "587/587 [==============================] - 0s 414us/step - loss: 0.4305 - acc: 0.8569\n",
      "Epoch 53/100\n",
      "587/587 [==============================] - 0s 473us/step - loss: 0.4296 - acc: 0.8450\n",
      "Epoch 54/100\n",
      "587/587 [==============================] - 0s 418us/step - loss: 0.4261 - acc: 0.8450\n",
      "Epoch 55/100\n",
      "587/587 [==============================] - 0s 484us/step - loss: 0.4127 - acc: 0.8552\n",
      "Epoch 56/100\n",
      "587/587 [==============================] - 0s 436us/step - loss: 0.4084 - acc: 0.8433\n",
      "Epoch 57/100\n",
      "587/587 [==============================] - 0s 440us/step - loss: 0.4149 - acc: 0.8552\n",
      "Epoch 58/100\n",
      "587/587 [==============================] - 0s 437us/step - loss: 0.3855 - acc: 0.8637\n",
      "Epoch 59/100\n",
      "587/587 [==============================] - 0s 428us/step - loss: 0.3788 - acc: 0.8705\n",
      "Epoch 60/100\n",
      "587/587 [==============================] - 0s 425us/step - loss: 0.3798 - acc: 0.8637\n",
      "Epoch 61/100\n",
      "587/587 [==============================] - 0s 447us/step - loss: 0.3645 - acc: 0.8773\n",
      "Epoch 62/100\n",
      "587/587 [==============================] - 0s 420us/step - loss: 0.3609 - acc: 0.8773\n",
      "Epoch 63/100\n",
      "587/587 [==============================] - 0s 469us/step - loss: 0.3575 - acc: 0.8790\n",
      "Epoch 64/100\n",
      "587/587 [==============================] - 0s 463us/step - loss: 0.3561 - acc: 0.8654\n",
      "Epoch 65/100\n",
      "587/587 [==============================] - 0s 424us/step - loss: 0.3536 - acc: 0.8790\n",
      "Epoch 66/100\n",
      "587/587 [==============================] - 0s 439us/step - loss: 0.3569 - acc: 0.8807\n",
      "Epoch 67/100\n",
      "587/587 [==============================] - 0s 483us/step - loss: 0.3450 - acc: 0.8739\n",
      "Epoch 68/100\n",
      "587/587 [==============================] - 0s 477us/step - loss: 0.3390 - acc: 0.8842\n",
      "Epoch 69/100\n",
      "587/587 [==============================] - 0s 450us/step - loss: 0.3387 - acc: 0.8756\n",
      "Epoch 70/100\n",
      "587/587 [==============================] - 0s 479us/step - loss: 0.3335 - acc: 0.8842\n",
      "Epoch 71/100\n",
      "587/587 [==============================] - 0s 473us/step - loss: 0.3282 - acc: 0.8807\n",
      "Epoch 72/100\n",
      "587/587 [==============================] - 0s 519us/step - loss: 0.3417 - acc: 0.8807\n",
      "Epoch 73/100\n",
      "587/587 [==============================] - 0s 451us/step - loss: 0.3277 - acc: 0.8893\n",
      "Epoch 74/100\n",
      "587/587 [==============================] - 0s 487us/step - loss: 0.3280 - acc: 0.8756\n",
      "Epoch 75/100\n",
      "587/587 [==============================] - 0s 444us/step - loss: 0.3239 - acc: 0.8842\n",
      "Epoch 76/100\n",
      "587/587 [==============================] - 0s 482us/step - loss: 0.3242 - acc: 0.8739\n",
      "Epoch 77/100\n",
      "587/587 [==============================] - 0s 459us/step - loss: 0.3251 - acc: 0.8876 0s - loss: 0.3483 - acc: 0.\n",
      "Epoch 78/100\n",
      "587/587 [==============================] - 0s 432us/step - loss: 0.3191 - acc: 0.8842\n",
      "Epoch 79/100\n",
      "587/587 [==============================] - 0s 467us/step - loss: 0.3206 - acc: 0.8859\n",
      "Epoch 80/100\n",
      "587/587 [==============================] - 0s 475us/step - loss: 0.3193 - acc: 0.8807\n",
      "Epoch 81/100\n",
      "587/587 [==============================] - 0s 478us/step - loss: 0.3262 - acc: 0.8739\n",
      "Epoch 82/100\n",
      "587/587 [==============================] - 0s 493us/step - loss: 0.3105 - acc: 0.8927\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587/587 [==============================] - 0s 496us/step - loss: 0.3131 - acc: 0.8842\n",
      "Epoch 84/100\n",
      "587/587 [==============================] - 0s 526us/step - loss: 0.3107 - acc: 0.8910\n",
      "Epoch 85/100\n",
      "587/587 [==============================] - 0s 537us/step - loss: 0.3097 - acc: 0.8944\n",
      "Epoch 86/100\n",
      "587/587 [==============================] - 0s 482us/step - loss: 0.3105 - acc: 0.8859\n",
      "Epoch 87/100\n",
      "587/587 [==============================] - 0s 469us/step - loss: 0.3088 - acc: 0.8876\n",
      "Epoch 88/100\n",
      "587/587 [==============================] - 0s 526us/step - loss: 0.3059 - acc: 0.8944\n",
      "Epoch 89/100\n",
      "587/587 [==============================] - 0s 446us/step - loss: 0.3094 - acc: 0.8825\n",
      "Epoch 90/100\n",
      "587/587 [==============================] - 0s 443us/step - loss: 0.3031 - acc: 0.8859\n",
      "Epoch 91/100\n",
      "587/587 [==============================] - 0s 448us/step - loss: 0.3010 - acc: 0.8927\n",
      "Epoch 92/100\n",
      "587/587 [==============================] - 0s 444us/step - loss: 0.2997 - acc: 0.8927\n",
      "Epoch 93/100\n",
      "587/587 [==============================] - 0s 499us/step - loss: 0.3096 - acc: 0.8807\n",
      "Epoch 94/100\n",
      "587/587 [==============================] - 0s 516us/step - loss: 0.2993 - acc: 0.8893\n",
      "Epoch 95/100\n",
      "587/587 [==============================] - 0s 504us/step - loss: 0.3009 - acc: 0.8893\n",
      "Epoch 96/100\n",
      "587/587 [==============================] - 0s 542us/step - loss: 0.3036 - acc: 0.8876\n",
      "Epoch 97/100\n",
      "587/587 [==============================] - 0s 477us/step - loss: 0.3055 - acc: 0.8756\n",
      "Epoch 98/100\n",
      "587/587 [==============================] - 0s 478us/step - loss: 0.2955 - acc: 0.8927\n",
      "Epoch 99/100\n",
      "587/587 [==============================] - 0s 444us/step - loss: 0.2964 - acc: 0.8910\n",
      "Epoch 100/100\n",
      "587/587 [==============================] - 0s 462us/step - loss: 0.2986 - acc: 0.8876\n",
      "66/66 [==============================] - 1s 12ms/step\n",
      "acc: 81.82%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "588/588 [==============================] - 3s 4ms/step - loss: 0.6929 - acc: 0.5357\n",
      "Epoch 2/100\n",
      "588/588 [==============================] - 0s 488us/step - loss: 0.6920 - acc: 0.5510\n",
      "Epoch 3/100\n",
      "588/588 [==============================] - 0s 479us/step - loss: 0.6914 - acc: 0.5510\n",
      "Epoch 4/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.6909 - acc: 0.5510 0s - loss: 0.6940 - acc: 0.\n",
      "Epoch 5/100\n",
      "588/588 [==============================] - 0s 498us/step - loss: 0.6904 - acc: 0.5510\n",
      "Epoch 6/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.6900 - acc: 0.5510\n",
      "Epoch 7/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.6897 - acc: 0.5510\n",
      "Epoch 8/100\n",
      "588/588 [==============================] - 0s 503us/step - loss: 0.6894 - acc: 0.5510\n",
      "Epoch 9/100\n",
      "588/588 [==============================] - 0s 524us/step - loss: 0.6892 - acc: 0.5510\n",
      "Epoch 10/100\n",
      "588/588 [==============================] - 0s 522us/step - loss: 0.6889 - acc: 0.5510\n",
      "Epoch 11/100\n",
      "588/588 [==============================] - 0s 554us/step - loss: 0.6888 - acc: 0.5510\n",
      "Epoch 12/100\n",
      "588/588 [==============================] - 0s 518us/step - loss: 0.6887 - acc: 0.5510\n",
      "Epoch 13/100\n",
      "588/588 [==============================] - 0s 524us/step - loss: 0.6885 - acc: 0.5510\n",
      "Epoch 14/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.6884 - acc: 0.5510\n",
      "Epoch 15/100\n",
      "588/588 [==============================] - 0s 524us/step - loss: 0.6886 - acc: 0.5510\n",
      "Epoch 16/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.6883 - acc: 0.5510\n",
      "Epoch 17/100\n",
      "588/588 [==============================] - 0s 528us/step - loss: 0.6882 - acc: 0.5510\n",
      "Epoch 18/100\n",
      "588/588 [==============================] - 0s 523us/step - loss: 0.6882 - acc: 0.5510\n",
      "Epoch 19/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.6882 - acc: 0.5510\n",
      "Epoch 20/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 21/100\n",
      "588/588 [==============================] - 0s 546us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 22/100\n",
      "588/588 [==============================] - 0s 500us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 23/100\n",
      "588/588 [==============================] - 0s 557us/step - loss: 0.6881 - acc: 0.5510 0s - loss: 0.6892 - acc: 0.5\n",
      "Epoch 24/100\n",
      "588/588 [==============================] - 0s 484us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 25/100\n",
      "588/588 [==============================] - 0s 465us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 26/100\n",
      "588/588 [==============================] - 0s 452us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 27/100\n",
      "588/588 [==============================] - 0s 478us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 28/100\n",
      "588/588 [==============================] - 0s 450us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 29/100\n",
      "588/588 [==============================] - 0s 447us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 30/100\n",
      "588/588 [==============================] - 0s 501us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 31/100\n",
      "588/588 [==============================] - 0s 445us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 32/100\n",
      "588/588 [==============================] - 0s 424us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 33/100\n",
      "588/588 [==============================] - 0s 482us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 34/100\n",
      "588/588 [==============================] - 0s 467us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 35/100\n",
      "588/588 [==============================] - 0s 485us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 36/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 37/100\n",
      "588/588 [==============================] - 0s 461us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 38/100\n",
      "588/588 [==============================] - 0s 465us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 39/100\n",
      "588/588 [==============================] - 0s 435us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 40/100\n",
      "588/588 [==============================] - 0s 454us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 41/100\n",
      "588/588 [==============================] - 0s 470us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 42/100\n",
      "588/588 [==============================] - 0s 461us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 43/100\n",
      "588/588 [==============================] - 0s 456us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 44/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 45/100\n",
      "588/588 [==============================] - 0s 498us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 46/100\n",
      "588/588 [==============================] - 0s 475us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 47/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 48/100\n",
      "588/588 [==============================] - 0s 450us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 49/100\n",
      "588/588 [==============================] - 0s 483us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 50/100\n",
      "588/588 [==============================] - 0s 445us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 51/100\n",
      "588/588 [==============================] - 0s 439us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 52/100\n",
      "588/588 [==============================] - 0s 446us/step - loss: 0.6879 - acc: 0.5510\n",
      "Epoch 53/100\n",
      "588/588 [==============================] - 0s 482us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 54/100\n",
      "588/588 [==============================] - 0s 467us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 55/100\n",
      "588/588 [==============================] - 0s 471us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 56/100\n",
      "588/588 [==============================] - 0s 503us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 57/100\n",
      "588/588 [==============================] - 0s 518us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 58/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 59/100\n",
      "588/588 [==============================] - 0s 503us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 60/100\n",
      "588/588 [==============================] - 0s 475us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 61/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 62/100\n",
      "588/588 [==============================] - 0s 560us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 63/100\n",
      "588/588 [==============================] - 0s 544us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 64/100\n",
      "588/588 [==============================] - 0s 529us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 65/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 66/100\n",
      "588/588 [==============================] - 0s 573us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 67/100\n",
      "588/588 [==============================] - 0s 503us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 68/100\n",
      "588/588 [==============================] - 0s 539us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 69/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 70/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 71/100\n",
      "588/588 [==============================] - 0s 479us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 72/100\n",
      "588/588 [==============================] - 0s 585us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 73/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 74/100\n",
      "588/588 [==============================] - 0s 475us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 75/100\n",
      "588/588 [==============================] - 0s 609us/step - loss: 0.6881 - acc: 0.5510\n",
      "Epoch 76/100\n",
      "588/588 [==============================] - 0s 574us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 77/100\n",
      "588/588 [==============================] - 0s 535us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 78/100\n",
      "588/588 [==============================] - 0s 464us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 79/100\n",
      "588/588 [==============================] - 0s 629us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 80/100\n",
      "588/588 [==============================] - 0s 518us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 81/100\n",
      "588/588 [==============================] - 0s 528us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 82/100\n",
      "588/588 [==============================] - 0s 578us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 83/100\n",
      "588/588 [==============================] - 0s 639us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 84/100\n",
      "588/588 [==============================] - 0s 536us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 85/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 86/100\n",
      "588/588 [==============================] - 0s 607us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 87/100\n",
      "588/588 [==============================] - 0s 497us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 88/100\n",
      "588/588 [==============================] - 0s 555us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 89/100\n",
      "588/588 [==============================] - 0s 470us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 90/100\n",
      "588/588 [==============================] - 0s 491us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 91/100\n",
      "588/588 [==============================] - 0s 512us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 92/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 93/100\n",
      "588/588 [==============================] - 0s 477us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 94/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 95/100\n",
      "588/588 [==============================] - 0s 481us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 96/100\n",
      "588/588 [==============================] - 0s 528us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 97/100\n",
      "588/588 [==============================] - 0s 553us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 98/100\n",
      "588/588 [==============================] - 0s 522us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 99/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.6880 - acc: 0.5510\n",
      "Epoch 100/100\n",
      "588/588 [==============================] - 0s 491us/step - loss: 0.6880 - acc: 0.5510\n",
      "65/65 [==============================] - 1s 14ms/step\n",
      "acc: 50.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwku\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "588/588 [==============================] - 3s 5ms/step - loss: 0.6929 - acc: 0.5374\n",
      "Epoch 2/100\n",
      "588/588 [==============================] - 0s 497us/step - loss: 0.6924 - acc: 0.5425\n",
      "Epoch 3/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.6919 - acc: 0.5425\n",
      "Epoch 4/100\n",
      "588/588 [==============================] - 0s 562us/step - loss: 0.6915 - acc: 0.5425\n",
      "Epoch 5/100\n",
      "588/588 [==============================] - 0s 603us/step - loss: 0.6912 - acc: 0.5425\n",
      "Epoch 6/100\n",
      "588/588 [==============================] - 0s 602us/step - loss: 0.6909 - acc: 0.5425\n",
      "Epoch 7/100\n",
      "588/588 [==============================] - 0s 596us/step - loss: 0.6906 - acc: 0.5425\n",
      "Epoch 8/100\n",
      "588/588 [==============================] - 0s 607us/step - loss: 0.6903 - acc: 0.5425\n",
      "Epoch 9/100\n",
      "588/588 [==============================] - 0s 548us/step - loss: 0.6899 - acc: 0.5425\n",
      "Epoch 10/100\n",
      "588/588 [==============================] - 0s 465us/step - loss: 0.6896 - acc: 0.5425\n",
      "Epoch 11/100\n",
      "588/588 [==============================] - 0s 523us/step - loss: 0.6890 - acc: 0.5425 0s - loss: 0.6901 - acc: 0.5\n",
      "Epoch 12/100\n",
      "588/588 [==============================] - 0s 462us/step - loss: 0.6935 - acc: 0.5425\n",
      "Epoch 13/100\n",
      "588/588 [==============================] - 0s 553us/step - loss: 0.6880 - acc: 0.5425\n",
      "Epoch 14/100\n",
      "588/588 [==============================] - 0s 493us/step - loss: 0.6875 - acc: 0.5425\n",
      "Epoch 15/100\n",
      "588/588 [==============================] - 0s 492us/step - loss: 0.6868 - acc: 0.5425\n",
      "Epoch 16/100\n",
      "588/588 [==============================] - 0s 484us/step - loss: 0.6863 - acc: 0.5425\n",
      "Epoch 17/100\n",
      "588/588 [==============================] - 0s 490us/step - loss: 0.6858 - acc: 0.5425\n",
      "Epoch 18/100\n",
      "588/588 [==============================] - 0s 518us/step - loss: 0.6849 - acc: 0.5425\n",
      "Epoch 19/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.6840 - acc: 0.5425\n",
      "Epoch 20/100\n",
      "588/588 [==============================] - 0s 481us/step - loss: 0.6834 - acc: 0.5425\n",
      "Epoch 21/100\n",
      "588/588 [==============================] - 0s 492us/step - loss: 0.6821 - acc: 0.5425\n",
      "Epoch 22/100\n",
      "588/588 [==============================] - 0s 497us/step - loss: 0.6810 - acc: 0.5425\n",
      "Epoch 23/100\n",
      "588/588 [==============================] - 0s 489us/step - loss: 0.6793 - acc: 0.5425\n",
      "Epoch 24/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.6730 - acc: 0.5425\n",
      "Epoch 25/100\n",
      "588/588 [==============================] - 0s 434us/step - loss: 0.6783 - acc: 0.5425\n",
      "Epoch 26/100\n",
      "588/588 [==============================] - 0s 552us/step - loss: 0.6765 - acc: 0.5425\n",
      "Epoch 27/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.6662 - acc: 0.5425\n",
      "Epoch 28/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.6153 - acc: 0.5425\n",
      "Epoch 29/100\n",
      "588/588 [==============================] - 0s 494us/step - loss: 0.6040 - acc: 0.5425\n",
      "Epoch 30/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.5823 - acc: 0.5425\n",
      "Epoch 31/100\n",
      "588/588 [==============================] - 0s 563us/step - loss: 0.5482 - acc: 0.6173\n",
      "Epoch 32/100\n",
      "588/588 [==============================] - 0s 494us/step - loss: 0.5545 - acc: 0.7398\n",
      "Epoch 33/100\n",
      "588/588 [==============================] - 0s 485us/step - loss: 0.5305 - acc: 0.7789\n",
      "Epoch 34/100\n",
      "588/588 [==============================] - 0s 487us/step - loss: 0.5293 - acc: 0.7755\n",
      "Epoch 35/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.5111 - acc: 0.7789\n",
      "Epoch 36/100\n",
      "588/588 [==============================] - 0s 471us/step - loss: 0.5167 - acc: 0.7959\n",
      "Epoch 37/100\n",
      "588/588 [==============================] - 0s 539us/step - loss: 0.4988 - acc: 0.7976\n",
      "Epoch 38/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.4848 - acc: 0.8180\n",
      "Epoch 39/100\n",
      "588/588 [==============================] - 0s 441us/step - loss: 0.4990 - acc: 0.7942\n",
      "Epoch 40/100\n",
      "588/588 [==============================] - 0s 448us/step - loss: 0.4923 - acc: 0.7823\n",
      "Epoch 41/100\n",
      "588/588 [==============================] - 0s 506us/step - loss: 0.4908 - acc: 0.7959\n",
      "Epoch 42/100\n",
      "588/588 [==============================] - 0s 513us/step - loss: 0.4857 - acc: 0.8044\n",
      "Epoch 43/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.5064 - acc: 0.7755\n",
      "Epoch 44/100\n",
      "588/588 [==============================] - 0s 456us/step - loss: 0.4701 - acc: 0.8231\n",
      "Epoch 45/100\n",
      "588/588 [==============================] - 0s 491us/step - loss: 0.4701 - acc: 0.8146\n",
      "Epoch 46/100\n",
      "588/588 [==============================] - 0s 482us/step - loss: 0.4462 - acc: 0.8486\n",
      "Epoch 47/100\n",
      "588/588 [==============================] - 0s 546us/step - loss: 0.4321 - acc: 0.8520\n",
      "Epoch 48/100\n",
      "588/588 [==============================] - 0s 575us/step - loss: 0.5610 - acc: 0.6956\n",
      "Epoch 49/100\n",
      "588/588 [==============================] - 0s 565us/step - loss: 0.6883 - acc: 0.5408\n",
      "Epoch 50/100\n",
      "588/588 [==============================] - 0s 493us/step - loss: 0.6198 - acc: 0.6241\n",
      "Epoch 51/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.5067 - acc: 0.7415\n",
      "Epoch 52/100\n",
      "588/588 [==============================] - 0s 555us/step - loss: 0.4753 - acc: 0.7976\n",
      "Epoch 53/100\n",
      "588/588 [==============================] - 0s 533us/step - loss: 0.4664 - acc: 0.8061\n",
      "Epoch 54/100\n",
      "588/588 [==============================] - 0s 572us/step - loss: 0.4600 - acc: 0.8112\n",
      "Epoch 55/100\n",
      "588/588 [==============================] - 0s 521us/step - loss: 0.4620 - acc: 0.8027\n",
      "Epoch 56/100\n",
      "588/588 [==============================] - 0s 576us/step - loss: 0.4594 - acc: 0.8112\n",
      "Epoch 57/100\n",
      "588/588 [==============================] - 0s 544us/step - loss: 0.4533 - acc: 0.8163\n",
      "Epoch 58/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.4528 - acc: 0.8163\n",
      "Epoch 59/100\n",
      "588/588 [==============================] - 0s 524us/step - loss: 0.4667 - acc: 0.7993\n",
      "Epoch 60/100\n",
      "588/588 [==============================] - 0s 513us/step - loss: 0.4500 - acc: 0.8180\n",
      "Epoch 61/100\n",
      "588/588 [==============================] - 0s 569us/step - loss: 0.4612 - acc: 0.8044\n",
      "Epoch 62/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.4472 - acc: 0.8248\n",
      "Epoch 63/100\n",
      "588/588 [==============================] - 0s 508us/step - loss: 0.4409 - acc: 0.8231\n",
      "Epoch 64/100\n",
      "588/588 [==============================] - 0s 481us/step - loss: 0.4434 - acc: 0.8095\n",
      "Epoch 65/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.4410 - acc: 0.8095\n",
      "Epoch 66/100\n",
      "588/588 [==============================] - 0s 530us/step - loss: 0.4375 - acc: 0.8180\n",
      "Epoch 67/100\n",
      "588/588 [==============================] - 0s 559us/step - loss: 0.4330 - acc: 0.8248\n",
      "Epoch 68/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.4242 - acc: 0.8333\n",
      "Epoch 69/100\n",
      "588/588 [==============================] - 0s 485us/step - loss: 0.4148 - acc: 0.8418 0s - loss: 0.4395 - acc: 0.\n",
      "Epoch 70/100\n",
      "588/588 [==============================] - 0s 490us/step - loss: 0.3925 - acc: 0.8571 0s - loss: 0.4610 - acc: 0\n",
      "Epoch 71/100\n",
      "588/588 [==============================] - 0s 476us/step - loss: 0.3906 - acc: 0.8622\n",
      "Epoch 72/100\n",
      "588/588 [==============================] - 0s 495us/step - loss: 0.3985 - acc: 0.8656\n",
      "Epoch 73/100\n",
      "588/588 [==============================] - 0s 451us/step - loss: 0.4052 - acc: 0.8554\n",
      "Epoch 74/100\n",
      "588/588 [==============================] - 0s 467us/step - loss: 0.3899 - acc: 0.8520\n",
      "Epoch 75/100\n",
      "588/588 [==============================] - 0s 434us/step - loss: 0.3773 - acc: 0.8724\n",
      "Epoch 76/100\n",
      "588/588 [==============================] - 0s 461us/step - loss: 0.3806 - acc: 0.8554\n",
      "Epoch 77/100\n",
      "588/588 [==============================] - 0s 508us/step - loss: 0.3715 - acc: 0.8741\n",
      "Epoch 78/100\n",
      "588/588 [==============================] - 0s 496us/step - loss: 0.3925 - acc: 0.8537\n",
      "Epoch 79/100\n",
      "588/588 [==============================] - 0s 532us/step - loss: 0.3784 - acc: 0.8622\n",
      "Epoch 80/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.3608 - acc: 0.8759\n",
      "Epoch 81/100\n",
      "588/588 [==============================] - 0s 516us/step - loss: 0.3657 - acc: 0.8810\n",
      "Epoch 82/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.3673 - acc: 0.8673\n",
      "Epoch 83/100\n",
      "588/588 [==============================] - 0s 461us/step - loss: 0.3576 - acc: 0.8656\n",
      "Epoch 84/100\n",
      "588/588 [==============================] - 0s 497us/step - loss: 0.3798 - acc: 0.8673\n",
      "Epoch 85/100\n",
      "588/588 [==============================] - 0s 500us/step - loss: 0.3792 - acc: 0.8537\n",
      "Epoch 86/100\n",
      "588/588 [==============================] - 0s 490us/step - loss: 0.3596 - acc: 0.8724\n",
      "Epoch 87/100\n",
      "588/588 [==============================] - 0s 548us/step - loss: 0.3532 - acc: 0.8759\n",
      "Epoch 88/100\n",
      "588/588 [==============================] - 0s 500us/step - loss: 0.3511 - acc: 0.8810\n",
      "Epoch 89/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.3625 - acc: 0.8673\n",
      "Epoch 90/100\n",
      "588/588 [==============================] - 0s 448us/step - loss: 0.3478 - acc: 0.8776\n",
      "Epoch 91/100\n",
      "588/588 [==============================] - 0s 445us/step - loss: 0.4238 - acc: 0.8214\n",
      "Epoch 92/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.4023 - acc: 0.8401\n",
      "Epoch 93/100\n",
      "588/588 [==============================] - 0s 440us/step - loss: 0.3885 - acc: 0.8469\n",
      "Epoch 94/100\n",
      "588/588 [==============================] - 0s 494us/step - loss: 0.3774 - acc: 0.8554\n",
      "Epoch 95/100\n",
      "588/588 [==============================] - 0s 461us/step - loss: 0.3651 - acc: 0.8605\n",
      "Epoch 96/100\n",
      "588/588 [==============================] - 0s 486us/step - loss: 0.3627 - acc: 0.8690\n",
      "Epoch 97/100\n",
      "588/588 [==============================] - 0s 486us/step - loss: 0.3554 - acc: 0.8724\n",
      "Epoch 98/100\n",
      "588/588 [==============================] - 0s 443us/step - loss: 0.3616 - acc: 0.8656 0s - loss: 0.3461 - acc: 0.8\n",
      "Epoch 99/100\n",
      "588/588 [==============================] - 0s 494us/step - loss: 0.3402 - acc: 0.8793\n",
      "Epoch 100/100\n",
      "588/588 [==============================] - 0s 519us/step - loss: 0.3432 - acc: 0.8776\n",
      "65/65 [==============================] - 1s 14ms/step\n",
      "acc: 75.38%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "588/588 [==============================] - 3s 5ms/step - loss: 0.6928 - acc: 0.5476\n",
      "Epoch 2/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.6921 - acc: 0.5476\n",
      "Epoch 3/100\n",
      "588/588 [==============================] - 0s 444us/step - loss: 0.6915 - acc: 0.5476\n",
      "Epoch 4/100\n",
      "588/588 [==============================] - 0s 451us/step - loss: 0.6910 - acc: 0.5476\n",
      "Epoch 5/100\n",
      "588/588 [==============================] - 0s 471us/step - loss: 0.6905 - acc: 0.5476\n",
      "Epoch 6/100\n",
      "588/588 [==============================] - 0s 439us/step - loss: 0.6901 - acc: 0.5476\n",
      "Epoch 7/100\n",
      "588/588 [==============================] - 0s 447us/step - loss: 0.6926 - acc: 0.5476\n",
      "Epoch 8/100\n",
      "588/588 [==============================] - 0s 450us/step - loss: 0.6895 - acc: 0.5476\n",
      "Epoch 9/100\n",
      "588/588 [==============================] - 0s 464us/step - loss: 0.6892 - acc: 0.5476\n",
      "Epoch 10/100\n",
      "588/588 [==============================] - 0s 476us/step - loss: 0.6889 - acc: 0.5476\n",
      "Epoch 11/100\n",
      "588/588 [==============================] - 0s 440us/step - loss: 0.6887 - acc: 0.5476\n",
      "Epoch 12/100\n",
      "588/588 [==============================] - 0s 460us/step - loss: 0.6885 - acc: 0.5476\n",
      "Epoch 13/100\n",
      "588/588 [==============================] - 0s 445us/step - loss: 0.6882 - acc: 0.5476\n",
      "Epoch 14/100\n",
      "588/588 [==============================] - 0s 488us/step - loss: 0.6881 - acc: 0.5476\n",
      "Epoch 15/100\n",
      "588/588 [==============================] - 0s 470us/step - loss: 0.6878 - acc: 0.5476\n",
      "Epoch 16/100\n",
      "588/588 [==============================] - 0s 440us/step - loss: 0.6875 - acc: 0.5476\n",
      "Epoch 17/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.6872 - acc: 0.5476\n",
      "Epoch 18/100\n",
      "588/588 [==============================] - 0s 439us/step - loss: 0.6870 - acc: 0.5476\n",
      "Epoch 19/100\n",
      "588/588 [==============================] - 0s 444us/step - loss: 0.6865 - acc: 0.5476\n",
      "Epoch 20/100\n",
      "588/588 [==============================] - 0s 428us/step - loss: 0.6858 - acc: 0.5476\n",
      "Epoch 21/100\n",
      "588/588 [==============================] - 0s 458us/step - loss: 0.6893 - acc: 0.5476\n",
      "Epoch 22/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.6859 - acc: 0.5476\n",
      "Epoch 23/100\n",
      "588/588 [==============================] - 0s 441us/step - loss: 0.6854 - acc: 0.5476\n",
      "Epoch 24/100\n",
      "588/588 [==============================] - 0s 491us/step - loss: 0.6851 - acc: 0.5476\n",
      "Epoch 25/100\n",
      "588/588 [==============================] - 0s 534us/step - loss: 0.6847 - acc: 0.5476\n",
      "Epoch 26/100\n",
      "588/588 [==============================] - 0s 479us/step - loss: 0.6843 - acc: 0.5476\n",
      "Epoch 27/100\n",
      "588/588 [==============================] - 0s 512us/step - loss: 0.6838 - acc: 0.5476\n",
      "Epoch 28/100\n",
      "588/588 [==============================] - 0s 483us/step - loss: 0.6833 - acc: 0.5476\n",
      "Epoch 29/100\n",
      "588/588 [==============================] - 0s 477us/step - loss: 0.6825 - acc: 0.5476\n",
      "Epoch 30/100\n",
      "588/588 [==============================] - 0s 481us/step - loss: 0.6817 - acc: 0.5476\n",
      "Epoch 31/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.6680 - acc: 0.5476\n",
      "Epoch 32/100\n",
      "588/588 [==============================] - 0s 479us/step - loss: 0.6650 - acc: 0.5476\n",
      "Epoch 33/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.7224 - acc: 0.5476\n",
      "Epoch 34/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.5990 - acc: 0.5476\n",
      "Epoch 35/100\n",
      "588/588 [==============================] - 0s 451us/step - loss: 0.6012 - acc: 0.5476\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588/588 [==============================] - 0s 521us/step - loss: 0.5877 - acc: 0.5476\n",
      "Epoch 37/100\n",
      "588/588 [==============================] - 0s 445us/step - loss: 0.5751 - acc: 0.5476\n",
      "Epoch 38/100\n",
      "588/588 [==============================] - 0s 500us/step - loss: 0.5666 - acc: 0.6939\n",
      "Epoch 39/100\n",
      "588/588 [==============================] - 0s 557us/step - loss: 0.5432 - acc: 0.7466\n",
      "Epoch 40/100\n",
      "588/588 [==============================] - 0s 527us/step - loss: 0.5403 - acc: 0.7670\n",
      "Epoch 41/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.5376 - acc: 0.7568\n",
      "Epoch 42/100\n",
      "588/588 [==============================] - 0s 522us/step - loss: 0.5277 - acc: 0.7721\n",
      "Epoch 43/100\n",
      "588/588 [==============================] - 0s 512us/step - loss: 0.5234 - acc: 0.7670\n",
      "Epoch 44/100\n",
      "588/588 [==============================] - 0s 507us/step - loss: 0.5200 - acc: 0.7755\n",
      "Epoch 45/100\n",
      "588/588 [==============================] - 0s 508us/step - loss: 0.5062 - acc: 0.7925\n",
      "Epoch 46/100\n",
      "588/588 [==============================] - 0s 534us/step - loss: 0.5071 - acc: 0.7738\n",
      "Epoch 47/100\n",
      "588/588 [==============================] - 0s 497us/step - loss: 0.4867 - acc: 0.8095\n",
      "Epoch 48/100\n",
      "588/588 [==============================] - 0s 490us/step - loss: 0.5312 - acc: 0.7415\n",
      "Epoch 49/100\n",
      "588/588 [==============================] - 0s 486us/step - loss: 0.4989 - acc: 0.7891\n",
      "Epoch 50/100\n",
      "588/588 [==============================] - 0s 500us/step - loss: 0.4953 - acc: 0.7908\n",
      "Epoch 51/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.4908 - acc: 0.7925\n",
      "Epoch 52/100\n",
      "588/588 [==============================] - 0s 493us/step - loss: 0.4880 - acc: 0.7891\n",
      "Epoch 53/100\n",
      "588/588 [==============================] - 0s 487us/step - loss: 0.4916 - acc: 0.7908\n",
      "Epoch 54/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.4875 - acc: 0.7857\n",
      "Epoch 55/100\n",
      "588/588 [==============================] - 0s 503us/step - loss: 0.4918 - acc: 0.7806\n",
      "Epoch 56/100\n",
      "588/588 [==============================] - 0s 467us/step - loss: 0.4752 - acc: 0.7976\n",
      "Epoch 57/100\n",
      "588/588 [==============================] - 0s 483us/step - loss: 0.4706 - acc: 0.8010 0s - loss: 0.5152 - acc: 0.\n",
      "Epoch 58/100\n",
      "588/588 [==============================] - 0s 470us/step - loss: 0.4741 - acc: 0.7993\n",
      "Epoch 59/100\n",
      "588/588 [==============================] - 0s 464us/step - loss: 0.4809 - acc: 0.7925\n",
      "Epoch 60/100\n",
      "588/588 [==============================] - 0s 446us/step - loss: 0.4698 - acc: 0.8078\n",
      "Epoch 61/100\n",
      "588/588 [==============================] - 0s 470us/step - loss: 0.4637 - acc: 0.8129\n",
      "Epoch 62/100\n",
      "588/588 [==============================] - 0s 439us/step - loss: 0.4665 - acc: 0.8010\n",
      "Epoch 63/100\n",
      "588/588 [==============================] - 0s 450us/step - loss: 0.4417 - acc: 0.8265\n",
      "Epoch 64/100\n",
      "588/588 [==============================] - 0s 443us/step - loss: 0.4964 - acc: 0.7687\n",
      "Epoch 65/100\n",
      "588/588 [==============================] - 0s 454us/step - loss: 0.4665 - acc: 0.7891\n",
      "Epoch 66/100\n",
      "588/588 [==============================] - 0s 424us/step - loss: 0.4658 - acc: 0.7942\n",
      "Epoch 67/100\n",
      "588/588 [==============================] - 0s 436us/step - loss: 0.4653 - acc: 0.8044\n",
      "Epoch 68/100\n",
      "588/588 [==============================] - 0s 474us/step - loss: 0.4580 - acc: 0.8044\n",
      "Epoch 69/100\n",
      "588/588 [==============================] - 0s 469us/step - loss: 0.4559 - acc: 0.8061\n",
      "Epoch 70/100\n",
      "588/588 [==============================] - 0s 451us/step - loss: 0.4488 - acc: 0.8044\n",
      "Epoch 71/100\n",
      "588/588 [==============================] - 0s 480us/step - loss: 0.4607 - acc: 0.7976\n",
      "Epoch 72/100\n",
      "588/588 [==============================] - 0s 464us/step - loss: 0.4459 - acc: 0.8146\n",
      "Epoch 73/100\n",
      "588/588 [==============================] - 0s 443us/step - loss: 0.4440 - acc: 0.8112\n",
      "Epoch 74/100\n",
      "588/588 [==============================] - 0s 427us/step - loss: 0.4422 - acc: 0.8180\n",
      "Epoch 75/100\n",
      "588/588 [==============================] - 0s 458us/step - loss: 0.4358 - acc: 0.8146\n",
      "Epoch 76/100\n",
      "588/588 [==============================] - 0s 486us/step - loss: 0.4308 - acc: 0.8265\n",
      "Epoch 77/100\n",
      "588/588 [==============================] - 0s 474us/step - loss: 0.4292 - acc: 0.8265\n",
      "Epoch 78/100\n",
      "588/588 [==============================] - 0s 502us/step - loss: 0.4214 - acc: 0.8282\n",
      "Epoch 79/100\n",
      "588/588 [==============================] - 0s 490us/step - loss: 0.4175 - acc: 0.8384\n",
      "Epoch 80/100\n",
      "588/588 [==============================] - 0s 523us/step - loss: 0.3946 - acc: 0.8486\n",
      "Epoch 81/100\n",
      "588/588 [==============================] - 0s 481us/step - loss: 0.4098 - acc: 0.8469\n",
      "Epoch 82/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.3960 - acc: 0.8486\n",
      "Epoch 83/100\n",
      "588/588 [==============================] - 0s 488us/step - loss: 0.3845 - acc: 0.8622\n",
      "Epoch 84/100\n",
      "588/588 [==============================] - 0s 450us/step - loss: 0.3872 - acc: 0.8554\n",
      "Epoch 85/100\n",
      "588/588 [==============================] - 0s 448us/step - loss: 0.4273 - acc: 0.8299\n",
      "Epoch 86/100\n",
      "588/588 [==============================] - 0s 465us/step - loss: 0.3925 - acc: 0.8520\n",
      "Epoch 87/100\n",
      "588/588 [==============================] - 0s 471us/step - loss: 0.3768 - acc: 0.8571\n",
      "Epoch 88/100\n",
      "588/588 [==============================] - 0s 454us/step - loss: 0.4020 - acc: 0.8384\n",
      "Epoch 89/100\n",
      "588/588 [==============================] - 0s 442us/step - loss: 0.3913 - acc: 0.8435\n",
      "Epoch 90/100\n",
      "588/588 [==============================] - 0s 501us/step - loss: 0.3807 - acc: 0.8554\n",
      "Epoch 91/100\n",
      "588/588 [==============================] - 0s 511us/step - loss: 0.3803 - acc: 0.8469\n",
      "Epoch 92/100\n",
      "588/588 [==============================] - 0s 461us/step - loss: 0.3763 - acc: 0.8571\n",
      "Epoch 93/100\n",
      "588/588 [==============================] - 0s 477us/step - loss: 0.3976 - acc: 0.8401\n",
      "Epoch 94/100\n",
      "588/588 [==============================] - 0s 443us/step - loss: 0.3655 - acc: 0.8605\n",
      "Epoch 95/100\n",
      "588/588 [==============================] - 0s 491us/step - loss: 0.4020 - acc: 0.8333\n",
      "Epoch 96/100\n",
      "588/588 [==============================] - 0s 495us/step - loss: 0.3977 - acc: 0.8554\n",
      "Epoch 97/100\n",
      "588/588 [==============================] - 0s 529us/step - loss: 0.4370 - acc: 0.8112\n",
      "Epoch 98/100\n",
      "588/588 [==============================] - 0s 590us/step - loss: 0.3954 - acc: 0.8418\n",
      "Epoch 99/100\n",
      "588/588 [==============================] - 0s 565us/step - loss: 0.3785 - acc: 0.8537\n",
      "Epoch 100/100\n",
      "588/588 [==============================] - 0s 625us/step - loss: 0.3679 - acc: 0.8554\n",
      "65/65 [==============================] - 1s 17ms/step\n",
      "acc: 87.69%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "588/588 [==============================] - 3s 5ms/step - loss: 0.6498 - acc: 0.5935\n",
      "Epoch 2/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.6433 - acc: 0.6820\n",
      "Epoch 3/100\n",
      "588/588 [==============================] - 0s 480us/step - loss: 0.6380 - acc: 0.6820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "588/588 [==============================] - 0s 474us/step - loss: 0.6354 - acc: 0.6888\n",
      "Epoch 5/100\n",
      "588/588 [==============================] - 0s 481us/step - loss: 0.6321 - acc: 0.6888\n",
      "Epoch 6/100\n",
      "588/588 [==============================] - 0s 500us/step - loss: 0.6312 - acc: 0.6820\n",
      "Epoch 7/100\n",
      "588/588 [==============================] - 0s 476us/step - loss: 0.6275 - acc: 0.6939\n",
      "Epoch 8/100\n",
      "588/588 [==============================] - 0s 465us/step - loss: 0.6268 - acc: 0.6973\n",
      "Epoch 9/100\n",
      "588/588 [==============================] - 0s 467us/step - loss: 0.6206 - acc: 0.6905\n",
      "Epoch 10/100\n",
      "588/588 [==============================] - 0s 455us/step - loss: 0.6204 - acc: 0.6956\n",
      "Epoch 11/100\n",
      "588/588 [==============================] - 0s 433us/step - loss: 0.6206 - acc: 0.6871\n",
      "Epoch 12/100\n",
      "588/588 [==============================] - 0s 467us/step - loss: 0.6173 - acc: 0.7109\n",
      "Epoch 13/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.6098 - acc: 0.7160\n",
      "Epoch 14/100\n",
      "588/588 [==============================] - 0s 449us/step - loss: 0.6076 - acc: 0.7109\n",
      "Epoch 15/100\n",
      "588/588 [==============================] - 0s 482us/step - loss: 0.6011 - acc: 0.7126\n",
      "Epoch 16/100\n",
      "588/588 [==============================] - 0s 450us/step - loss: 0.6019 - acc: 0.7126\n",
      "Epoch 17/100\n",
      "588/588 [==============================] - 0s 523us/step - loss: 0.5936 - acc: 0.7109\n",
      "Epoch 18/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.5897 - acc: 0.7075\n",
      "Epoch 19/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.5851 - acc: 0.7143\n",
      "Epoch 20/100\n",
      "588/588 [==============================] - 0s 553us/step - loss: 0.5828 - acc: 0.7211\n",
      "Epoch 21/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.5870 - acc: 0.7296\n",
      "Epoch 22/100\n",
      "588/588 [==============================] - 0s 535us/step - loss: 0.5721 - acc: 0.7228\n",
      "Epoch 23/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.5715 - acc: 0.7177\n",
      "Epoch 24/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.5676 - acc: 0.7296\n",
      "Epoch 25/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.5546 - acc: 0.7364\n",
      "Epoch 26/100\n",
      "588/588 [==============================] - 0s 493us/step - loss: 0.5605 - acc: 0.7381\n",
      "Epoch 27/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.5472 - acc: 0.7364\n",
      "Epoch 28/100\n",
      "588/588 [==============================] - 0s 510us/step - loss: 0.5458 - acc: 0.7721\n",
      "Epoch 29/100\n",
      "588/588 [==============================] - 0s 502us/step - loss: 0.5295 - acc: 0.7534\n",
      "Epoch 30/100\n",
      "588/588 [==============================] - 0s 436us/step - loss: 0.5210 - acc: 0.7721\n",
      "Epoch 31/100\n",
      "588/588 [==============================] - 0s 569us/step - loss: 0.5106 - acc: 0.7857\n",
      "Epoch 32/100\n",
      "588/588 [==============================] - 0s 583us/step - loss: 0.5341 - acc: 0.7840\n",
      "Epoch 33/100\n",
      "588/588 [==============================] - 0s 548us/step - loss: 0.5047 - acc: 0.7908\n",
      "Epoch 34/100\n",
      "588/588 [==============================] - 0s 590us/step - loss: 0.4818 - acc: 0.8129\n",
      "Epoch 35/100\n",
      "588/588 [==============================] - 0s 585us/step - loss: 0.4603 - acc: 0.8299\n",
      "Epoch 36/100\n",
      "588/588 [==============================] - 0s 565us/step - loss: 0.4515 - acc: 0.8333\n",
      "Epoch 37/100\n",
      "588/588 [==============================] - 0s 507us/step - loss: 0.4553 - acc: 0.8299\n",
      "Epoch 38/100\n",
      "588/588 [==============================] - 0s 528us/step - loss: 0.4296 - acc: 0.8537\n",
      "Epoch 39/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.4278 - acc: 0.8503\n",
      "Epoch 40/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.4218 - acc: 0.8316\n",
      "Epoch 41/100\n",
      "588/588 [==============================] - 0s 573us/step - loss: 0.4141 - acc: 0.8469\n",
      "Epoch 42/100\n",
      "588/588 [==============================] - 0s 573us/step - loss: 0.4143 - acc: 0.8469\n",
      "Epoch 43/100\n",
      "588/588 [==============================] - 0s 589us/step - loss: 0.3886 - acc: 0.8639\n",
      "Epoch 44/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.4137 - acc: 0.8367\n",
      "Epoch 45/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.4013 - acc: 0.8554\n",
      "Epoch 46/100\n",
      "588/588 [==============================] - 0s 582us/step - loss: 0.4023 - acc: 0.8486\n",
      "Epoch 47/100\n",
      "588/588 [==============================] - 0s 550us/step - loss: 0.3881 - acc: 0.8520\n",
      "Epoch 48/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.3760 - acc: 0.8605\n",
      "Epoch 49/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.3719 - acc: 0.8690\n",
      "Epoch 50/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.3666 - acc: 0.8520\n",
      "Epoch 51/100\n",
      "588/588 [==============================] - 0s 489us/step - loss: 0.3575 - acc: 0.8622\n",
      "Epoch 52/100\n",
      "588/588 [==============================] - 0s 545us/step - loss: 0.3613 - acc: 0.8588\n",
      "Epoch 53/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.3613 - acc: 0.8656\n",
      "Epoch 54/100\n",
      "588/588 [==============================] - 0s 511us/step - loss: 0.3535 - acc: 0.8656\n",
      "Epoch 55/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.3545 - acc: 0.8656\n",
      "Epoch 56/100\n",
      "588/588 [==============================] - 0s 536us/step - loss: 0.3466 - acc: 0.8741\n",
      "Epoch 57/100\n",
      "588/588 [==============================] - 0s 538us/step - loss: 0.3418 - acc: 0.8690\n",
      "Epoch 58/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.3418 - acc: 0.8690\n",
      "Epoch 59/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.3361 - acc: 0.8776\n",
      "Epoch 60/100\n",
      "588/588 [==============================] - 0s 524us/step - loss: 0.3407 - acc: 0.8724\n",
      "Epoch 61/100\n",
      "588/588 [==============================] - 0s 500us/step - loss: 0.3456 - acc: 0.8622\n",
      "Epoch 62/100\n",
      "588/588 [==============================] - 0s 514us/step - loss: 0.3375 - acc: 0.8810 0s - loss: 0.3204 - acc: 0.8\n",
      "Epoch 63/100\n",
      "588/588 [==============================] - 0s 556us/step - loss: 0.3246 - acc: 0.8827\n",
      "Epoch 64/100\n",
      "588/588 [==============================] - 0s 538us/step - loss: 0.3291 - acc: 0.8690\n",
      "Epoch 65/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.3296 - acc: 0.8793\n",
      "Epoch 66/100\n",
      "588/588 [==============================] - 0s 510us/step - loss: 0.3231 - acc: 0.8776\n",
      "Epoch 67/100\n",
      "588/588 [==============================] - 0s 565us/step - loss: 0.3196 - acc: 0.8844\n",
      "Epoch 68/100\n",
      "588/588 [==============================] - 0s 502us/step - loss: 0.3197 - acc: 0.8776\n",
      "Epoch 69/100\n",
      "588/588 [==============================] - 0s 513us/step - loss: 0.3261 - acc: 0.8810\n",
      "Epoch 70/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.3203 - acc: 0.8724\n",
      "Epoch 71/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.3126 - acc: 0.8759\n",
      "Epoch 72/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.3141 - acc: 0.8741\n",
      "Epoch 73/100\n",
      "588/588 [==============================] - 0s 510us/step - loss: 0.3164 - acc: 0.8793\n",
      "Epoch 74/100\n",
      "588/588 [==============================] - 0s 573us/step - loss: 0.3322 - acc: 0.8639\n",
      "Epoch 75/100\n",
      "588/588 [==============================] - 0s 506us/step - loss: 0.3091 - acc: 0.8810\n",
      "Epoch 76/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.3116 - acc: 0.8861\n",
      "Epoch 77/100\n",
      "588/588 [==============================] - 0s 514us/step - loss: 0.3084 - acc: 0.8776\n",
      "Epoch 78/100\n",
      "588/588 [==============================] - 0s 507us/step - loss: 0.3086 - acc: 0.8793\n",
      "Epoch 79/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.3066 - acc: 0.8724\n",
      "Epoch 80/100\n",
      "588/588 [==============================] - 0s 532us/step - loss: 0.3035 - acc: 0.8793\n",
      "Epoch 81/100\n",
      "588/588 [==============================] - 0s 535us/step - loss: 0.3035 - acc: 0.8827\n",
      "Epoch 82/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.2978 - acc: 0.8946\n",
      "Epoch 83/100\n",
      "588/588 [==============================] - 0s 589us/step - loss: 0.3004 - acc: 0.8929\n",
      "Epoch 84/100\n",
      "588/588 [==============================] - 0s 619us/step - loss: 0.3015 - acc: 0.8776\n",
      "Epoch 85/100\n",
      "588/588 [==============================] - 0s 543us/step - loss: 0.2964 - acc: 0.8827\n",
      "Epoch 86/100\n",
      "588/588 [==============================] - 0s 579us/step - loss: 0.2917 - acc: 0.8963\n",
      "Epoch 87/100\n",
      "588/588 [==============================] - 0s 536us/step - loss: 0.2991 - acc: 0.8776\n",
      "Epoch 88/100\n",
      "588/588 [==============================] - 0s 536us/step - loss: 0.2916 - acc: 0.8878\n",
      "Epoch 89/100\n",
      "588/588 [==============================] - 0s 550us/step - loss: 0.2946 - acc: 0.8776\n",
      "Epoch 90/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.2900 - acc: 0.8895\n",
      "Epoch 91/100\n",
      "588/588 [==============================] - 0s 538us/step - loss: 0.2967 - acc: 0.8810\n",
      "Epoch 92/100\n",
      "588/588 [==============================] - 0s 584us/step - loss: 0.2902 - acc: 0.8793\n",
      "Epoch 93/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.2861 - acc: 0.8844\n",
      "Epoch 94/100\n",
      "588/588 [==============================] - 0s 566us/step - loss: 0.2922 - acc: 0.8827\n",
      "Epoch 95/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.2957 - acc: 0.8929\n",
      "Epoch 96/100\n",
      "588/588 [==============================] - 0s 569us/step - loss: 0.2875 - acc: 0.8844\n",
      "Epoch 97/100\n",
      "588/588 [==============================] - 0s 554us/step - loss: 0.2882 - acc: 0.8912\n",
      "Epoch 98/100\n",
      "588/588 [==============================] - 0s 544us/step - loss: 0.2905 - acc: 0.8793\n",
      "Epoch 99/100\n",
      "588/588 [==============================] - 0s 512us/step - loss: 0.2859 - acc: 0.8878\n",
      "Epoch 100/100\n",
      "588/588 [==============================] - 0s 519us/step - loss: 0.2922 - acc: 0.8827\n",
      "65/65 [==============================] - 1s 16ms/step\n",
      "acc: 81.54%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "588/588 [==============================] - 3s 5ms/step - loss: 0.7098 - acc: 0.5578\n",
      "Epoch 2/100\n",
      "588/588 [==============================] - 0s 560us/step - loss: 0.6857 - acc: 0.5578\n",
      "Epoch 3/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.6709 - acc: 0.5578\n",
      "Epoch 4/100\n",
      "588/588 [==============================] - 0s 553us/step - loss: 0.6563 - acc: 0.5578\n",
      "Epoch 5/100\n",
      "588/588 [==============================] - 0s 540us/step - loss: 0.6501 - acc: 0.5578\n",
      "Epoch 6/100\n",
      "588/588 [==============================] - 0s 563us/step - loss: 0.6489 - acc: 0.5884\n",
      "Epoch 7/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.6430 - acc: 0.6990\n",
      "Epoch 8/100\n",
      "588/588 [==============================] - 0s 527us/step - loss: 0.6410 - acc: 0.6905\n",
      "Epoch 9/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.6397 - acc: 0.7024\n",
      "Epoch 10/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.6343 - acc: 0.7024\n",
      "Epoch 11/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.6300 - acc: 0.7058\n",
      "Epoch 12/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.6300 - acc: 0.6939\n",
      "Epoch 13/100\n",
      "588/588 [==============================] - 0s 582us/step - loss: 0.6277 - acc: 0.6905\n",
      "Epoch 14/100\n",
      "588/588 [==============================] - 0s 569us/step - loss: 0.6256 - acc: 0.6973\n",
      "Epoch 15/100\n",
      "588/588 [==============================] - 0s 576us/step - loss: 0.6213 - acc: 0.7041\n",
      "Epoch 16/100\n",
      "588/588 [==============================] - 0s 563us/step - loss: 0.6191 - acc: 0.7041\n",
      "Epoch 17/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.6143 - acc: 0.7058\n",
      "Epoch 18/100\n",
      "588/588 [==============================] - 0s 591us/step - loss: 0.6072 - acc: 0.7160\n",
      "Epoch 19/100\n",
      "588/588 [==============================] - 0s 519us/step - loss: 0.6132 - acc: 0.7092\n",
      "Epoch 20/100\n",
      "588/588 [==============================] - 0s 557us/step - loss: 0.6016 - acc: 0.7126\n",
      "Epoch 21/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.6039 - acc: 0.7126\n",
      "Epoch 22/100\n",
      "588/588 [==============================] - 0s 535us/step - loss: 0.5974 - acc: 0.7245\n",
      "Epoch 23/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.5976 - acc: 0.7075\n",
      "Epoch 24/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.5885 - acc: 0.7262\n",
      "Epoch 25/100\n",
      "588/588 [==============================] - 0s 488us/step - loss: 0.5958 - acc: 0.7228\n",
      "Epoch 26/100\n",
      "588/588 [==============================] - 0s 568us/step - loss: 0.5763 - acc: 0.7279\n",
      "Epoch 27/100\n",
      "588/588 [==============================] - 0s 564us/step - loss: 0.5744 - acc: 0.7262\n",
      "Epoch 28/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.5633 - acc: 0.7296\n",
      "Epoch 29/100\n",
      "588/588 [==============================] - 0s 551us/step - loss: 0.5557 - acc: 0.7398\n",
      "Epoch 30/100\n",
      "588/588 [==============================] - 0s 519us/step - loss: 0.5489 - acc: 0.7449\n",
      "Epoch 31/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.6196 - acc: 0.6905\n",
      "Epoch 32/100\n",
      "588/588 [==============================] - 0s 532us/step - loss: 0.5862 - acc: 0.7024\n",
      "Epoch 33/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.5615 - acc: 0.7126\n",
      "Epoch 34/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.5423 - acc: 0.7398\n",
      "Epoch 35/100\n",
      "588/588 [==============================] - 0s 533us/step - loss: 0.5405 - acc: 0.7449\n",
      "Epoch 36/100\n",
      "588/588 [==============================] - 0s 503us/step - loss: 0.5290 - acc: 0.7500\n",
      "Epoch 37/100\n",
      "588/588 [==============================] - 0s 521us/step - loss: 0.5210 - acc: 0.7483\n",
      "Epoch 38/100\n",
      "588/588 [==============================] - 0s 543us/step - loss: 0.5084 - acc: 0.7755\n",
      "Epoch 39/100\n",
      "588/588 [==============================] - 0s 532us/step - loss: 0.5034 - acc: 0.7840\n",
      "Epoch 40/100\n",
      "588/588 [==============================] - 0s 534us/step - loss: 0.5186 - acc: 0.7517\n",
      "Epoch 41/100\n",
      "588/588 [==============================] - 0s 574us/step - loss: 0.5003 - acc: 0.7806\n",
      "Epoch 42/100\n",
      "588/588 [==============================] - 0s 596us/step - loss: 0.5071 - acc: 0.7772\n",
      "Epoch 43/100\n",
      "588/588 [==============================] - 0s 530us/step - loss: 0.4723 - acc: 0.8061\n",
      "Epoch 44/100\n",
      "588/588 [==============================] - 0s 559us/step - loss: 0.5259 - acc: 0.7619\n",
      "Epoch 45/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.5548 - acc: 0.7092 0s - loss: 0.5696 - acc: 0.6\n",
      "Epoch 46/100\n",
      "588/588 [==============================] - 0s 512us/step - loss: 0.5272 - acc: 0.7381\n",
      "Epoch 47/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.5148 - acc: 0.7466\n",
      "Epoch 48/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.4951 - acc: 0.7704\n",
      "Epoch 49/100\n",
      "588/588 [==============================] - 0s 550us/step - loss: 0.4951 - acc: 0.7619\n",
      "Epoch 50/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.4841 - acc: 0.7772\n",
      "Epoch 51/100\n",
      "588/588 [==============================] - 0s 534us/step - loss: 0.4828 - acc: 0.7772\n",
      "Epoch 52/100\n",
      "588/588 [==============================] - 0s 572us/step - loss: 0.4772 - acc: 0.7806\n",
      "Epoch 53/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.4796 - acc: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.4739 - acc: 0.7925\n",
      "Epoch 55/100\n",
      "588/588 [==============================] - 0s 532us/step - loss: 0.4580 - acc: 0.8044\n",
      "Epoch 56/100\n",
      "588/588 [==============================] - 0s 501us/step - loss: 0.4405 - acc: 0.8265\n",
      "Epoch 57/100\n",
      "588/588 [==============================] - 0s 516us/step - loss: 0.4354 - acc: 0.8316\n",
      "Epoch 58/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.4656 - acc: 0.8180\n",
      "Epoch 59/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.4310 - acc: 0.8350\n",
      "Epoch 60/100\n",
      "588/588 [==============================] - 0s 593us/step - loss: 0.4142 - acc: 0.8435\n",
      "Epoch 61/100\n",
      "588/588 [==============================] - 0s 632us/step - loss: 0.4255 - acc: 0.8299\n",
      "Epoch 62/100\n",
      "588/588 [==============================] - 0s 601us/step - loss: 0.4154 - acc: 0.8384\n",
      "Epoch 63/100\n",
      "588/588 [==============================] - 0s 680us/step - loss: 0.4257 - acc: 0.8248\n",
      "Epoch 64/100\n",
      "588/588 [==============================] - 0s 691us/step - loss: 0.4060 - acc: 0.8418\n",
      "Epoch 65/100\n",
      "588/588 [==============================] - 0s 604us/step - loss: 0.4283 - acc: 0.8231\n",
      "Epoch 66/100\n",
      "588/588 [==============================] - 0s 562us/step - loss: 0.4350 - acc: 0.8299\n",
      "Epoch 67/100\n",
      "588/588 [==============================] - ETA: 0s - loss: 0.3959 - acc: 0.849 - 0s 579us/step - loss: 0.3930 - acc: 0.8503\n",
      "Epoch 68/100\n",
      "588/588 [==============================] - 0s 534us/step - loss: 0.4709 - acc: 0.8010\n",
      "Epoch 69/100\n",
      "588/588 [==============================] - 0s 564us/step - loss: 0.4286 - acc: 0.8418\n",
      "Epoch 70/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.3914 - acc: 0.8537\n",
      "Epoch 71/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.3850 - acc: 0.8452\n",
      "Epoch 72/100\n",
      "588/588 [==============================] - 0s 589us/step - loss: 0.4090 - acc: 0.8316\n",
      "Epoch 73/100\n",
      "588/588 [==============================] - 0s 574us/step - loss: 0.3902 - acc: 0.8486\n",
      "Epoch 74/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.4047 - acc: 0.8401\n",
      "Epoch 75/100\n",
      "588/588 [==============================] - 0s 530us/step - loss: 0.3944 - acc: 0.8401\n",
      "Epoch 76/100\n",
      "588/588 [==============================] - 0s 580us/step - loss: 0.3765 - acc: 0.8520\n",
      "Epoch 77/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.3791 - acc: 0.8656\n",
      "Epoch 78/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.3801 - acc: 0.8520\n",
      "Epoch 79/100\n",
      "588/588 [==============================] - 0s 561us/step - loss: 0.3874 - acc: 0.8537\n",
      "Epoch 80/100\n",
      "588/588 [==============================] - 0s 530us/step - loss: 0.3764 - acc: 0.8673\n",
      "Epoch 81/100\n",
      "588/588 [==============================] - 0s 552us/step - loss: 0.3639 - acc: 0.8639\n",
      "Epoch 82/100\n",
      "588/588 [==============================] - 0s 527us/step - loss: 0.3686 - acc: 0.8724\n",
      "Epoch 83/100\n",
      "588/588 [==============================] - 0s 501us/step - loss: 0.3627 - acc: 0.8639\n",
      "Epoch 84/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.3765 - acc: 0.8656\n",
      "Epoch 85/100\n",
      "588/588 [==============================] - 0s 518us/step - loss: 0.3772 - acc: 0.8588\n",
      "Epoch 86/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.3935 - acc: 0.8350\n",
      "Epoch 87/100\n",
      "588/588 [==============================] - 0s 528us/step - loss: 0.3877 - acc: 0.8554\n",
      "Epoch 88/100\n",
      "588/588 [==============================] - 0s 523us/step - loss: 0.3725 - acc: 0.8639\n",
      "Epoch 89/100\n",
      "588/588 [==============================] - 0s 535us/step - loss: 0.3801 - acc: 0.8588\n",
      "Epoch 90/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.3851 - acc: 0.8486\n",
      "Epoch 91/100\n",
      "588/588 [==============================] - 0s 583us/step - loss: 0.3660 - acc: 0.8571\n",
      "Epoch 92/100\n",
      "588/588 [==============================] - 0s 502us/step - loss: 0.3668 - acc: 0.8537\n",
      "Epoch 93/100\n",
      "588/588 [==============================] - 0s 506us/step - loss: 0.3500 - acc: 0.8724\n",
      "Epoch 94/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.3713 - acc: 0.8554\n",
      "Epoch 95/100\n",
      "588/588 [==============================] - 0s 521us/step - loss: 0.3788 - acc: 0.8673\n",
      "Epoch 96/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.3885 - acc: 0.8571\n",
      "Epoch 97/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.3633 - acc: 0.8707\n",
      "Epoch 98/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.3571 - acc: 0.8741\n",
      "Epoch 99/100\n",
      "588/588 [==============================] - 0s 530us/step - loss: 0.3666 - acc: 0.8520\n",
      "Epoch 100/100\n",
      "588/588 [==============================] - 0s 518us/step - loss: 0.3649 - acc: 0.8707\n",
      "65/65 [==============================] - 1s 17ms/step\n",
      "acc: 89.23%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "588/588 [==============================] - 3s 6ms/step - loss: 0.6542 - acc: 0.6599\n",
      "Epoch 2/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.6521 - acc: 0.6854\n",
      "Epoch 3/100\n",
      "588/588 [==============================] - 0s 535us/step - loss: 0.6488 - acc: 0.6871\n",
      "Epoch 4/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.6427 - acc: 0.6922\n",
      "Epoch 5/100\n",
      "588/588 [==============================] - 0s 556us/step - loss: 0.6385 - acc: 0.6820\n",
      "Epoch 6/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.6411 - acc: 0.6820\n",
      "Epoch 7/100\n",
      "588/588 [==============================] - 0s 480us/step - loss: 0.6383 - acc: 0.6905\n",
      "Epoch 8/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.6384 - acc: 0.6888\n",
      "Epoch 9/100\n",
      "588/588 [==============================] - 0s 554us/step - loss: 0.6351 - acc: 0.6939\n",
      "Epoch 10/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.6310 - acc: 0.6871\n",
      "Epoch 11/100\n",
      "588/588 [==============================] - 0s 577us/step - loss: 0.6302 - acc: 0.6905\n",
      "Epoch 12/100\n",
      "588/588 [==============================] - 0s 607us/step - loss: 0.6283 - acc: 0.6888\n",
      "Epoch 13/100\n",
      "588/588 [==============================] - 0s 559us/step - loss: 0.6313 - acc: 0.6922\n",
      "Epoch 14/100\n",
      "588/588 [==============================] - 0s 584us/step - loss: 0.6252 - acc: 0.6990\n",
      "Epoch 15/100\n",
      "588/588 [==============================] - 0s 532us/step - loss: 0.6206 - acc: 0.7075\n",
      "Epoch 16/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.6170 - acc: 0.7075\n",
      "Epoch 17/100\n",
      "588/588 [==============================] - 0s 555us/step - loss: 0.6121 - acc: 0.7126\n",
      "Epoch 18/100\n",
      "588/588 [==============================] - 0s 567us/step - loss: 0.6070 - acc: 0.7279\n",
      "Epoch 19/100\n",
      "588/588 [==============================] - 0s 504us/step - loss: 0.6016 - acc: 0.7415\n",
      "Epoch 20/100\n",
      "588/588 [==============================] - 0s 509us/step - loss: 0.5892 - acc: 0.7551\n",
      "Epoch 21/100\n",
      "588/588 [==============================] - 0s 543us/step - loss: 0.5787 - acc: 0.7704\n",
      "Epoch 22/100\n",
      "588/588 [==============================] - 0s 507us/step - loss: 0.5688 - acc: 0.7534\n",
      "Epoch 23/100\n",
      "588/588 [==============================] - 0s 550us/step - loss: 0.5769 - acc: 0.7432\n",
      "Epoch 24/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.5425 - acc: 0.7891\n",
      "Epoch 25/100\n",
      "588/588 [==============================] - 0s 536us/step - loss: 0.5428 - acc: 0.7670\n",
      "Epoch 26/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.5066 - acc: 0.8231\n",
      "Epoch 27/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.4848 - acc: 0.8282\n",
      "Epoch 28/100\n",
      "588/588 [==============================] - 0s 516us/step - loss: 0.4705 - acc: 0.8401\n",
      "Epoch 29/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.4634 - acc: 0.8486\n",
      "Epoch 30/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.4416 - acc: 0.8571\n",
      "Epoch 31/100\n",
      "588/588 [==============================] - 0s 565us/step - loss: 0.4260 - acc: 0.8639\n",
      "Epoch 32/100\n",
      "588/588 [==============================] - 0s 501us/step - loss: 0.4135 - acc: 0.8571\n",
      "Epoch 33/100\n",
      "588/588 [==============================] - 0s 527us/step - loss: 0.4089 - acc: 0.8673\n",
      "Epoch 34/100\n",
      "588/588 [==============================] - 0s 510us/step - loss: 0.4043 - acc: 0.8690\n",
      "Epoch 35/100\n",
      "588/588 [==============================] - 0s 514us/step - loss: 0.3927 - acc: 0.8639\n",
      "Epoch 36/100\n",
      "588/588 [==============================] - 0s 536us/step - loss: 0.3924 - acc: 0.8673\n",
      "Epoch 37/100\n",
      "588/588 [==============================] - 0s 539us/step - loss: 0.3811 - acc: 0.8759\n",
      "Epoch 38/100\n",
      "588/588 [==============================] - 0s 539us/step - loss: 0.3902 - acc: 0.8690\n",
      "Epoch 39/100\n",
      "588/588 [==============================] - 0s 540us/step - loss: 0.3701 - acc: 0.8810\n",
      "Epoch 40/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.3686 - acc: 0.8776\n",
      "Epoch 41/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.3643 - acc: 0.8793\n",
      "Epoch 42/100\n",
      "588/588 [==============================] - 0s 521us/step - loss: 0.3563 - acc: 0.8844 0s - loss: 0.3175 - acc: 0.\n",
      "Epoch 43/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.3554 - acc: 0.8844\n",
      "Epoch 44/100\n",
      "588/588 [==============================] - 0s 607us/step - loss: 0.3516 - acc: 0.8827\n",
      "Epoch 45/100\n",
      "588/588 [==============================] - 0s 566us/step - loss: 0.3544 - acc: 0.8793\n",
      "Epoch 46/100\n",
      "588/588 [==============================] - 0s 586us/step - loss: 0.3459 - acc: 0.8844\n",
      "Epoch 47/100\n",
      "588/588 [==============================] - 0s 582us/step - loss: 0.3459 - acc: 0.8741\n",
      "Epoch 48/100\n",
      "588/588 [==============================] - 0s 578us/step - loss: 0.3375 - acc: 0.8861\n",
      "Epoch 49/100\n",
      "588/588 [==============================] - 0s 586us/step - loss: 0.3374 - acc: 0.8844\n",
      "Epoch 50/100\n",
      "588/588 [==============================] - 0s 575us/step - loss: 0.3418 - acc: 0.8810\n",
      "Epoch 51/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.3361 - acc: 0.8827\n",
      "Epoch 52/100\n",
      "588/588 [==============================] - 0s 566us/step - loss: 0.3302 - acc: 0.8878\n",
      "Epoch 53/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.3265 - acc: 0.8878\n",
      "Epoch 54/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.3251 - acc: 0.8895\n",
      "Epoch 55/100\n",
      "588/588 [==============================] - 0s 566us/step - loss: 0.3235 - acc: 0.8912\n",
      "Epoch 56/100\n",
      "588/588 [==============================] - 0s 568us/step - loss: 0.3192 - acc: 0.8929\n",
      "Epoch 57/100\n",
      "588/588 [==============================] - 0s 580us/step - loss: 0.3241 - acc: 0.8878\n",
      "Epoch 58/100\n",
      "588/588 [==============================] - 0s 583us/step - loss: 0.3145 - acc: 0.8946\n",
      "Epoch 59/100\n",
      "588/588 [==============================] - 0s 615us/step - loss: 0.3158 - acc: 0.8827\n",
      "Epoch 60/100\n",
      "588/588 [==============================] - 0s 541us/step - loss: 0.3167 - acc: 0.8810\n",
      "Epoch 61/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.3085 - acc: 0.8912\n",
      "Epoch 62/100\n",
      "588/588 [==============================] - 0s 539us/step - loss: 0.3100 - acc: 0.8929\n",
      "Epoch 63/100\n",
      "588/588 [==============================] - 0s 535us/step - loss: 0.3114 - acc: 0.8861\n",
      "Epoch 64/100\n",
      "588/588 [==============================] - 0s 567us/step - loss: 0.3064 - acc: 0.8912\n",
      "Epoch 65/100\n",
      "588/588 [==============================] - 0s 550us/step - loss: 0.3097 - acc: 0.8929\n",
      "Epoch 66/100\n",
      "588/588 [==============================] - 0s 519us/step - loss: 0.3068 - acc: 0.8929\n",
      "Epoch 67/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.3022 - acc: 0.8878\n",
      "Epoch 68/100\n",
      "588/588 [==============================] - 0s 573us/step - loss: 0.3030 - acc: 0.8861\n",
      "Epoch 69/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.3011 - acc: 0.8912\n",
      "Epoch 70/100\n",
      "588/588 [==============================] - 0s 555us/step - loss: 0.2962 - acc: 0.8946\n",
      "Epoch 71/100\n",
      "588/588 [==============================] - 0s 650us/step - loss: 0.3026 - acc: 0.8946\n",
      "Epoch 72/100\n",
      "588/588 [==============================] - 0s 552us/step - loss: 0.2936 - acc: 0.8963\n",
      "Epoch 73/100\n",
      "588/588 [==============================] - 0s 538us/step - loss: 0.2977 - acc: 0.8895\n",
      "Epoch 74/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.2988 - acc: 0.8980\n",
      "Epoch 75/100\n",
      "588/588 [==============================] - 0s 569us/step - loss: 0.2985 - acc: 0.8878\n",
      "Epoch 76/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.2947 - acc: 0.8946\n",
      "Epoch 77/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.2950 - acc: 0.8946\n",
      "Epoch 78/100\n",
      "588/588 [==============================] - 0s 563us/step - loss: 0.2926 - acc: 0.8963\n",
      "Epoch 79/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.2931 - acc: 0.8980\n",
      "Epoch 80/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.2904 - acc: 0.8929\n",
      "Epoch 81/100\n",
      "588/588 [==============================] - 0s 508us/step - loss: 0.2904 - acc: 0.8895\n",
      "Epoch 82/100\n",
      "588/588 [==============================] - 0s 571us/step - loss: 0.2905 - acc: 0.8895\n",
      "Epoch 83/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.2892 - acc: 0.8895\n",
      "Epoch 84/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.2863 - acc: 0.8912\n",
      "Epoch 85/100\n",
      "588/588 [==============================] - 0s 481us/step - loss: 0.2849 - acc: 0.8980\n",
      "Epoch 86/100\n",
      "588/588 [==============================] - 0s 523us/step - loss: 0.2879 - acc: 0.9048\n",
      "Epoch 87/100\n",
      "588/588 [==============================] - 0s 487us/step - loss: 0.2856 - acc: 0.8878\n",
      "Epoch 88/100\n",
      "588/588 [==============================] - 0s 487us/step - loss: 0.2877 - acc: 0.8963\n",
      "Epoch 89/100\n",
      "588/588 [==============================] - 0s 488us/step - loss: 0.2879 - acc: 0.8963\n",
      "Epoch 90/100\n",
      "588/588 [==============================] - 0s 487us/step - loss: 0.2837 - acc: 0.8929\n",
      "Epoch 91/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.2856 - acc: 0.8963\n",
      "Epoch 92/100\n",
      "588/588 [==============================] - 0s 502us/step - loss: 0.2861 - acc: 0.8929\n",
      "Epoch 93/100\n",
      "588/588 [==============================] - 0s 477us/step - loss: 0.2828 - acc: 0.8912\n",
      "Epoch 94/100\n",
      "588/588 [==============================] - 0s 556us/step - loss: 0.2853 - acc: 0.8929\n",
      "Epoch 95/100\n",
      "588/588 [==============================] - 0s 579us/step - loss: 0.2813 - acc: 0.8946\n",
      "Epoch 96/100\n",
      "588/588 [==============================] - 0s 531us/step - loss: 0.2826 - acc: 0.8946\n",
      "Epoch 97/100\n",
      "588/588 [==============================] - 0s 582us/step - loss: 0.2832 - acc: 0.8963\n",
      "Epoch 98/100\n",
      "588/588 [==============================] - 0s 605us/step - loss: 0.2845 - acc: 0.8929\n",
      "Epoch 99/100\n",
      "588/588 [==============================] - 0s 592us/step - loss: 0.2804 - acc: 0.8963\n",
      "Epoch 100/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.2819 - acc: 0.8878\n",
      "65/65 [==============================] - 1s 16ms/step\n",
      "acc: 84.62%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        (None, 46, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 46, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 23, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 23, 10)            310       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 11, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 111       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 463\n",
      "Trainable params: 463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "588/588 [==============================] - 3s 5ms/step - loss: 0.6930 - acc: 0.5238\n",
      "Epoch 2/100\n",
      "588/588 [==============================] - 0s 477us/step - loss: 0.6926 - acc: 0.5340\n",
      "Epoch 3/100\n",
      "588/588 [==============================] - 0s 494us/step - loss: 0.6923 - acc: 0.5340\n",
      "Epoch 4/100\n",
      "588/588 [==============================] - 0s 471us/step - loss: 0.6921 - acc: 0.5340\n",
      "Epoch 5/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.6919 - acc: 0.5340\n",
      "Epoch 6/100\n",
      "588/588 [==============================] - 0s 440us/step - loss: 0.6917 - acc: 0.5340\n",
      "Epoch 7/100\n",
      "588/588 [==============================] - 0s 461us/step - loss: 0.6916 - acc: 0.5340\n",
      "Epoch 8/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.6915 - acc: 0.5340\n",
      "Epoch 9/100\n",
      "588/588 [==============================] - 0s 505us/step - loss: 0.6914 - acc: 0.5340\n",
      "Epoch 10/100\n",
      "588/588 [==============================] - 0s 537us/step - loss: 0.6913 - acc: 0.5340\n",
      "Epoch 11/100\n",
      "588/588 [==============================] - 0s 502us/step - loss: 0.6912 - acc: 0.5340\n",
      "Epoch 12/100\n",
      "588/588 [==============================] - 0s 466us/step - loss: 0.6912 - acc: 0.5340\n",
      "Epoch 13/100\n",
      "588/588 [==============================] - 0s 485us/step - loss: 0.6912 - acc: 0.5340\n",
      "Epoch 14/100\n",
      "588/588 [==============================] - 0s 453us/step - loss: 0.6911 - acc: 0.5340\n",
      "Epoch 15/100\n",
      "588/588 [==============================] - 0s 473us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 16/100\n",
      "588/588 [==============================] - 0s 456us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 17/100\n",
      "588/588 [==============================] - 0s 472us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 18/100\n",
      "588/588 [==============================] - 0s 572us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 19/100\n",
      "588/588 [==============================] - 0s 568us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 20/100\n",
      "588/588 [==============================] - 0s 601us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 21/100\n",
      "588/588 [==============================] - 0s 583us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 22/100\n",
      "588/588 [==============================] - 0s 581us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 23/100\n",
      "588/588 [==============================] - 0s 588us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 24/100\n",
      "588/588 [==============================] - 0s 456us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 25/100\n",
      "588/588 [==============================] - 0s 521us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 26/100\n",
      "588/588 [==============================] - 0s 512us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 27/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 28/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 29/100\n",
      "588/588 [==============================] - 0s 544us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 30/100\n",
      "588/588 [==============================] - 0s 528us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 31/100\n",
      "588/588 [==============================] - 0s 626us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 32/100\n",
      "588/588 [==============================] - 0s 525us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 33/100\n",
      "588/588 [==============================] - 0s 508us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 34/100\n",
      "588/588 [==============================] - ETA: 0s - loss: 0.6904 - acc: 0.537 - 0s 501us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 35/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 36/100\n",
      "588/588 [==============================] - 0s 529us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 37/100\n",
      "588/588 [==============================] - 0s 522us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 38/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 39/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 40/100\n",
      "588/588 [==============================] - 0s 501us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 41/100\n",
      "588/588 [==============================] - 0s 530us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 42/100\n",
      "588/588 [==============================] - 0s 496us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 43/100\n",
      "588/588 [==============================] - 0s 451us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 44/100\n",
      "588/588 [==============================] - 0s 467us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 45/100\n",
      "588/588 [==============================] - 0s 480us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 46/100\n",
      "588/588 [==============================] - 0s 498us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 47/100\n",
      "588/588 [==============================] - 0s 558us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 48/100\n",
      "588/588 [==============================] - 0s 542us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 49/100\n",
      "588/588 [==============================] - 0s 499us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 50/100\n",
      "588/588 [==============================] - 0s 523us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 51/100\n",
      "588/588 [==============================] - 0s 471us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 52/100\n",
      "588/588 [==============================] - 0s 529us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 53/100\n",
      "588/588 [==============================] - 0s 475us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 54/100\n",
      "588/588 [==============================] - 0s 486us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 55/100\n",
      "588/588 [==============================] - 0s 503us/step - loss: 0.6909 - acc: 0.5340 0s - loss: 0.6844 - acc: 0\n",
      "Epoch 56/100\n",
      "588/588 [==============================] - 0s 473us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 57/100\n",
      "588/588 [==============================] - 0s 456us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 58/100\n",
      "588/588 [==============================] - 0s 515us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 59/100\n",
      "588/588 [==============================] - 0s 446us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 60/100\n",
      "588/588 [==============================] - 0s 507us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 61/100\n",
      "588/588 [==============================] - 0s 554us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 62/100\n",
      "588/588 [==============================] - 0s 482us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 63/100\n",
      "588/588 [==============================] - 0s 483us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 64/100\n",
      "588/588 [==============================] - 0s 474us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 65/100\n",
      "588/588 [==============================] - 0s 543us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 66/100\n",
      "588/588 [==============================] - 0s 538us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 67/100\n",
      "588/588 [==============================] - 0s 464us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 68/100\n",
      "588/588 [==============================] - 0s 482us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 69/100\n",
      "588/588 [==============================] - 0s 517us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 70/100\n",
      "588/588 [==============================] - 0s 508us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 71/100\n",
      "588/588 [==============================] - 0s 506us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 72/100\n",
      "588/588 [==============================] - 0s 560us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 73/100\n",
      "588/588 [==============================] - 0s 495us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 74/100\n",
      "588/588 [==============================] - 0s 569us/step - loss: 0.6910 - acc: 0.5340\n",
      "Epoch 75/100\n",
      "588/588 [==============================] - 0s 573us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 76/100\n",
      "588/588 [==============================] - 0s 544us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 77/100\n",
      "588/588 [==============================] - 0s 570us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 78/100\n",
      "588/588 [==============================] - 0s 563us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 79/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 80/100\n",
      "588/588 [==============================] - 0s 590us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 81/100\n",
      "588/588 [==============================] - 0s 584us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 82/100\n",
      "588/588 [==============================] - 0s 610us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 83/100\n",
      "588/588 [==============================] - 0s 592us/step - loss: 0.6909 - acc: 0.5340 0s - loss: 0.6936 - acc: 0.\n",
      "Epoch 84/100\n",
      "588/588 [==============================] - 0s 591us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 85/100\n",
      "588/588 [==============================] - 0s 588us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 86/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 87/100\n",
      "588/588 [==============================] - 0s 574us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 88/100\n",
      "588/588 [==============================] - 0s 547us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 89/100\n",
      "588/588 [==============================] - 0s 554us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 90/100\n",
      "588/588 [==============================] - 0s 555us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 91/100\n",
      "588/588 [==============================] - 0s 555us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 92/100\n",
      "588/588 [==============================] - 0s 544us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 93/100\n",
      "588/588 [==============================] - 0s 539us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 94/100\n",
      "588/588 [==============================] - 0s 578us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 95/100\n",
      "588/588 [==============================] - 0s 575us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 96/100\n",
      "588/588 [==============================] - 0s 539us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 97/100\n",
      "588/588 [==============================] - 0s 526us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 98/100\n",
      "588/588 [==============================] - 0s 516us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 99/100\n",
      "588/588 [==============================] - 0s 534us/step - loss: 0.6909 - acc: 0.5340\n",
      "Epoch 100/100\n",
      "588/588 [==============================] - 0s 520us/step - loss: 0.6909 - acc: 0.5340\n",
      "65/65 [==============================] - 1s 17ms/step\n",
      "acc: 66.15%\n",
      "Evaluation Methods 10th-Mean values\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Accuracy  0.7990209790209791\n",
      "Precision  nan\n",
      "Recall  0.6374467009025833\n",
      "F1  nan\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv1D, Dense, MaxPool1D, Flatten, Input\n",
    "import numpy as np\n",
    "\n",
    "i = 0\n",
    "for train, test in kf.split(df0):\n",
    "\n",
    "    y_train = df0.iloc[train][df0.columns[-1]]\n",
    "    x_train = df0.iloc[train].drop(df0.columns[-1], axis=1)\n",
    "    x_train = np.expand_dims(x_train, axis=2)\n",
    "    \n",
    "    \n",
    "    y_test = df0.iloc[test][df0.columns[-1]]\n",
    "    x_test = df0.iloc[test].drop(df0.columns[-1], axis=1)\n",
    "    x_test = np.expand_dims(x_test, axis=2)\n",
    "    \n",
    "\n",
    "    # Initializing the Sequential model from KERAS.\n",
    "    model = Sequential()\n",
    "\n",
    "    inp =  Input(shape=(46, 1))\n",
    "    conv = Conv1D(filters=10, kernel_size=3, activation='relu', padding='same')(inp)\n",
    "    pool = MaxPool1D(pool_size=2)(conv)\n",
    "    conv1 = Conv1D(filters=10, kernel_size=3, activation='relu', padding='same')(pool)\n",
    "    pool1 = MaxPool1D(pool_size=2)(conv1)\n",
    "    flat = Flatten()(pool1)\n",
    "    relu = Dense(1, activation='relu',  kernel_initializer=\"uniform\")(flat)    \n",
    "    dense = Dense(1, activation='sigmoid',  kernel_initializer=\"uniform\")(relu)\n",
    "    model = Model(inp, dense)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Fitting the model\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=10)\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "    \n",
    "    \n",
    "    predict = np.where(model.predict(x_test)>0.5,1,0)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test.values, predict.reshape(len(predict))).ravel()    \n",
    "    \n",
    "    \n",
    "    Accuracy  = (TP+TN)/(TP+TN+FP+FN)\n",
    "    Precision = (TP)/(TP+FP)\n",
    "    Recall = (TP)/(TP+FN)\n",
    "    F1 = (2*Precision*Recall)/(Precision + Recall)\n",
    "    \n",
    "    aAccuracy[0][i] = Accuracy\n",
    "    aPrecision[0][i] = Precision\n",
    "    aRecall[0][i] = Recall\n",
    "    aF1[0][i] = F1\n",
    "\n",
    "    i = i + 1        \n",
    "    \n",
    "i = 0\n",
    "print(\"Evaluation Methods 10th-Mean values\")    \n",
    "print(\"-\"*50)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy \", aAccuracy[0].mean())\n",
    "print(\"Precision \", aPrecision[0].mean())\n",
    "print(\"Recall \", aRecall[0].mean())\n",
    "print(\"F1 \", aF1[0].mean())    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
